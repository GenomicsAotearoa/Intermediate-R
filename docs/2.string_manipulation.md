# String manipulation

!!! note "Learning objectives"

    * Construct regular expressions
    * Find and count patterns in strings
    * Replace and subset (sub-)strings
    * Concatenate strings

## Can't I change it in Excel?

Sure, go ahead for small datasets and *ad hoc* analyses. However, can we be confident of being consistent for large datasets? Did we miss a few cells? Did we introduce extra punctuation? [Can Excel handle the amount of data?](https://www.bbc.com/news/technology-54423988) A good understanding of string manipulation can be useful for data cleaning (as mentioned before) and come in handy for many situations. For example:

- [Extracting statistics](https://stackoverflow.com/a/23760100) and [formatting them for plots](https://stackoverflow.com/a/63553243)
- [Using sub-strings as table keys](https://stackoverflow.com/a/71145164)
- [Pattern extraction](https://stackoverflow.com/a/38021237)
- [Manipulating URLs](https://stackoverflow.com/a/65152288)

In this lesson, we will learn how to use functions from the `stringr` package to manipulate and extract strings from taxonomic lineages in the `tax` data frame.

!!! note "Biological strings"

    At the fundamental level, all biological sequences (i.e., DNA, RNA, and amino acid) are strings. While the functions covered here can handle sequences, more is needed to extract biological relevance from them. When we think about biological sequences such as nucleic or amino acid sequences, we are interested in the relationships within and between strings (e.g., translations, alignments, *k*-mers, secondary structures, etc.). R has some packages that can handle such operations (e.g., `seqinr`, `Biostrings`, `DADA2`; see other packages in the Bioconductor repository). For those analyses, other programming languages offer better support and computational efficiencies.

## Regular expressions

A common thread (pun intended) in all string-based operations is regular expression (AKA *regex* or *regexp*). You probably have some experience with it if you have used **`sed`** or **`awk`** in **`bash`**. Formally, regular expressions are characters that represent finite sets of characters and the operations that can be performed on them. It is helpful to think of them as patterns.

Consider this example:

`[0-9]+.*_(log|chk)\\.txt`

The pattern is read from left to right. Let's break it down:

- `[0-9]` is a set of numbers from 0 to 9. The square brackets (`[]`) are meta-characters that allow matches to ranges (as in this example) or individual characters.
- `+` indicates that the pattern preceding it should occur $\ge$ 1 time(s)
- `.*` means to match anything `.` $\ge$ 0 times `*`
- `_` is just an underscore
- `(log|chk)` means to match either `log` or `chk` as a word. The `|` functions as an OR operator and the round brackets `()` indicate that the patterns inside them must be interpreted as a word.
- `\\.` matches a literal dot `.` where the double backslashes `\\` mean to "escape" the pattern following it

Based on the pattern/expression, we can safely assume that it should match a text file with a date or process number as a prefix, followed by some description and the output type.

In most cases, learning to construct regular expressions is based on trial and error and many Google searches. To soften the learning curve, the `stringr` team compiled a helpful [cheat sheet](https://rstudio.github.io/cheatsheets/strings.pdf) we can reference.

## Wrangling taxonomy

### Obtaining microbial taxonomy from DNA sequences

A major aim of microbial ecology is the identification of populations across an environment. We do that by sequencing the amplicon of the 16S small subunit ribosomal RNA gene, the standard taxonomic marker. Then, sequences are clustered based on sequence similarity (to reduce redundancy and improve computational efficiency) and then assigned a taxonomic lineage using a classifier that compares our sequence data with those in a reference database (popular options are SILVA and Greengenes 2). Depending on how similar and well-represented the sampled sequences are to those in the database, our sequences will be assigned names and ranks ranging from domain to species.

### Inspecting taxonomy

Let us begin by inspecting what our taxonomy looks like.

!!! r-project "code"

    ```r linenums="1"
    head(tax$Taxon)
    tail(tax$Taxon)
    ```

??? note "What's in a taxonomy"

    - A semicolon `;` separates the ranks
    - Ranks are given a single-letter prefix followed by `__`
    - Ranks are unevenly assigned. Some are identified down to species level, while only phylum is known in others.

### Detecting and extracting patterns

Some initial questions when inspecting the above taxonomy are:

1.  How well characterised are our sequences?
2.  Did we manage to retrieve biologically important taxa?

We can answer those questions using pattern detection.

**1. How well characterised are our sequences?**

Let's apply a heuristic and answer a simpler question: How many sequences were classified at each taxonomic rank (species, genus, family, order, class, phylum)? If there are large numbers of sequences that were only identified at higher taxonomic ranks, the system we are studying may harbour lots of novel microbial populations.

!!! r-project "code"

    ```r linenums="1"
    str_detect(tax$Taxon, "s__") %>%
      sum()
    ```

In the code above, we used the function `str_detect()` to find the species prefix `s__` in the `Taxon` column. The output of `str_detect()` is a logical/boolean vector. Thus, we use `sum()` to count the number of `TRUE` statements.

!!! tip "`stringr` syntax"

    Most functions in the `stringr` package accept arguments in this order:

    ```
    str_<name>(<vector>, <pattern>, ...)
    ```

??? "Question"

    What is the proportions of ASVs that have been assigned a lineage with rank of genus and phylum?

    ??? success "Solution"

        ```r linenums="1"
        sum(str_detect(tax$Taxon, "g__")) / nrow(tax)
        sum(str_detect(tax$Taxon, "p__")) / nrow(tax)
        ```

        It looks like our sequences are well characterised from the rank of genus and up.

**2. Did we manage to retrieve biologically important taxa?**

An ecosystem service that estuaries provide is nitrogen removal (via denitrification). These are usually performed by prokaryotes spanning the Bacterial and Archaeal domains. Their metabolic activity ensures that excess nitrogen is removed in gaseous form and thus prevents eutrophication. The starting substrate for denitrification is nitrate. Thus, reduced nitrogen must first be oxidised via nitrification. Two communities are involved in the conversion from reduced to oxidised nitrogen: - Ammonia oxidisers (usually has the prefix "Nitroso" in their taxonomy) - Nitrite oxidisers (usually has the prefix "Nitro" in their taxonomy)

Lets find out if we managed to sample any of them.

We will first need to subset the vector to retain those that have "Nitro" in their names. We will do this using `str_subset()`.

!!! r-project "code"

    ```r linenums="1"
    nitro <- str_subset(tax$Taxon, "__Nitro")
    length(nitro)
    ```

We will also take a finer look at their lineages so we can get a better idea of which community they belong to.

!!! r-project "code"

    ```r
    str_replace(
      nitro,
      "d__([^;]+);.*(Nitro[a-z]+).*",
      "\\1, \\2"
    ) %>% 
        unique()
    ```

The code above is quite complicated. Let's break it down.

- The function `str_replace()` is a flexible function that helps us extract and replace substrings depending on how the regex was constructed.
- `d__([^;]+);` looks for the sub-string `d__` followed by anything that is not a semicolon `[^;]+` more than once. The regex `[^<some_pattern>]` means to match anything that is NOT `<some_pattern>`. The round brackets `()` "captures" or "saves" the matches within it for replacement. This is followed by a semicolon (our rank separator) which is not captured but is present in the vector.
- `.*(Nitro[a-z]+).*` As we do not know at which rank the first instance of "Nitro" will appear, the regex `.*` will match anything `.` more than 0 times `*`. At the first "Nitro" it encounters, we will also look for any subsequent letters in small case ranging from 'a' to 'z' as represented by `Nitro[a-z]+`. Anything after that can be matched but is not captured.
- The last argument in the function specifies how the replacement string should look like. `\\1, \\2` replaces the output with the two patterns we captured separated by a comma and a space. Patterns are captured sequentially and must be referenced in the order which they appear in the original string. Therefore, if we wanted the "Nitro" part to be in front, we would reverse the order to `\\2, \\1`.

!!! tip "In case of failure..."

    If `str_replace()` cannot find matches for the given pattern, it will return the original string. This is a safety mechanism. We can choose to filter it out later if necessary.

    Run the following and see for yourself:

    !!! r-project "code"
    
        ```r linenums="1"
        str_replace(nitro, ".*p__([^;]+).*g__([^;]+).*", "\\1, \\2") %>% 
          unique()
        ```

!!! tip "Other useful functions"

    The functions `str_detect()` and `str_replace()` were the focus of this lesson for their flexible application and ease of visualising how regex and pattern capture works. Over the years, I have also found the functions below to be useful

    === Concatenation: `str_c()`, `paste()`

        Concatenates any number of string vectors per element (via the `sep =` argument) and/or across elements (via the `collapse =` argument)

        !!! r-project "code"

            ```r linenums="1"
            str_c(fruit[1:5], words[1:5], sep = ", ")
            str_c(fruit[1:5], collapse = "||")
            ```

    === Interpolation: `str_glue()`

        Evaluates expressions within `{}`, and then interpolate and concatenate them as strings. Very useful for programmatic use.

        !!! r-project "code"

            ```r linenums="1"
            prop_species <- sum(str_detect(tax$Taxon, "s__")) / nrow(tax)

            print(
              str_glue("QIIME2 classified {prop_species} of ASVs down to species level.")
            )
            ```

    === Separation by delimiter: `str_split()`

        Splits a string based on a provided delimiter and returns a character vector. If a character vector of length > 1 is provided as input, it will return a list of character vectors with each list element split based on the delimiter.

        !!! r-project "code"

            ```r linenums="1"
            str_split(nitro, pattern = "; ")
            ```

    === Whitespace trimming: `str_trim()`

        Removes whitespace at each end of the string. Very useful during data cleaning to make sure there are no trailing whitespaces that prevents downstream analyses.

        !!! r-project "code"
        
            ```r linenums="1"
            str_trim("   this has blanks   ")
            ```

    I highly recommend playing with the functions above to get a feel for how they work. `stringr` has some built-in character vectors that you can use on-the-fly as test cases: `fruit`, `words`, and `sentences`.

<!--
## Can't I change it in Excel? And other reasons to learn string manipulation.

You receive 10 files from someone. Five of the files all share the same naming convention (e.g., all column names are in full capitals). The other five files have a mix: some column names are lower case, some have the first letter capitalised, and some have a mix of full, first, and lower. You want all your files to have the same naming convention, so you know you'll want to change the column names for those five files. It's not many columns per file, and there are *only* five of them... Should you change those names in Excel?

Short answer: sure; long answer: *it depends*. If the data is small enough, Excel (or any spreadsheet software) is sufficient to fulfil your exploratory data analysis needs. However, for larger data sets, can you ensure that you have performed adequate, consistent, and robust data cleaning before analyses? Furthermore, if you are importing tabular data into R, you likely intend to perform statistical/numerical analyses and create a near-publication-level figure. Are your categorical variables consistent in their spelling? Did you check whether your European collaborator used a dot instead of a comma to delineate decimal points? Will you extract every statistic and string them together as your axis title for a 6-panel figure *by hand*? This is where understanding how to manipulate strings *en masse* is helpful. 

String manipulation is a fundamental skill in every programming language, and every language has its perks and quirks in handling strings. The common thread (pun intended) that ties them together is regular expressions which form the basis for patterns and their related operations. In bash, you may have used them to find or substitute parts of a string using `grep` or `sed`/`awk`. Here, we will cover some regular expressions as part of the examples and illustrate how they are interpreted in R. However, the topic of regular expression itself is vast. Please refer to the second page of the [stringr cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf) for comprehensive coverage of most of the regex in R.

!!! note "Biological strings"

    At the fundamental level, all biological sequences are strings. They can be handled with the functions covered here, but more is needed to extract biological relevance from them. When we think about biological sequences such as nucleic or amino acid sequences, we are interested in the relationships within and between strings (translations, alignments, *k*-mers, secondary structures, etc.). R has some packages that can handle such operations (e.g., seqinr, Biostrings, DADA2, see other packages in the Bioconductor repository). However, if these analyses are your primary interest, I suggest you look into other programming languages due to the inefficiencies of R in this regard.

## A brief detour

This lesson will briefly step away from *exploratory data analyses* and explore the realm of string-based methods in R via the **stringr** package. For this lesson, we will work with the following biological context: 

> A characteristic of estuarine sediment (where this data originated from) is its active nitrogen-cycling members of the prokaryotic community. For those participating in ammonia or nitrite oxidation, their lineages often have the prefix "Nitroso-" for putative ammonia oxidisers and "Nitro-" for putative nitrite oxidisers. However, specific lineages within these groups (assigned at varying taxonomic levels) bear the prefix but do not harbour the necessary genetic machinery for this function.

The above forms the boundary around the data which we will use for this lesson. Here, we will explore a group of functions at an abstract level. We aim to provide awareness to a set of tools to manipulate (i.e., search, subset, substitute) strings. Alongside that, we want you to be comfortable in constructing regular expressions. This can be daunting if you are new to them. However, we like you to keep in mind that it is both an engineering problem (maximising efficiency with pattern captures) and an art form (being creative and playful to adapt to situations). We stress that there are multiple ways (even within the same framework) to obtain similar results. Some functions are Swiss-army knives when paired with the right regex patterns.

## Subset a character vector

Lets prepare a character vector for us to work on.

!!! r-project "code"

    ```r
    nitros <- str_subset(tax$Taxon, "Nitro")
    head(nitros)
    ```

    > ```
    > [1] "d__Bacteria; p__Nitrospirota; c__Nitrospiria; o__Nitrospirales; f__Nitrospiraceae; g__Nitrospira; s__uncultured_Cytophaga"            
    > [2] "d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Nitrosococcales; f__Nitrosococcaceae; g__SZB85; s__uncultured_bacterium"   
    > [3] "d__Archaea; p__Crenarchaeota; c__Nitrososphaeria; o__Nitrosopumilales; f__Nitrosopumilaceae; g__Candidatus_Nitrosopumilus"            
    > [4] "d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Nitrosococcales; f__Nitrosococcaceae; g__SZB85; s__uncultured_bacterium"   
    > [5] "d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Nitrosococcales; f__Nitrosococcaceae; g__SZB85; s__uncultured_bacterium"   
    > [6] "d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Nitrosococcales; f__Nitrosococcaceae; g__FS142-36B-02; s__uncultured_gamma"
    > ```

This block of code returns a new character object `nitros`, which is made up of every element (line) where the pattern `"Nitro"` occurrs. In this case the pattern is a sub-string - any string that contains "Nitro" i.e., both "Nitro" and "Nitros" will be captured. 


??? tip "Equivalent code"

    === "Vector subset (tidyverse)"

        ```r
        tax$Taxon[str_detect(tax$Taxon, "Nitro")]
        ```

    === "Pattern matching (base R)"

        ```r
        grep(pattern = "Nitro", x = tax$Taxon, value = TRUE)
        ```

!!! note "Anatomy of pattern-based string functions in **stringr**"

    All stringr functions start with the string to operate on as the first argument. For functions that work with regex, the second argument is always the pattern. For functions that perform replacements, the pattern used for replacement is the third argument. For functions that perform searches, the third argument is usually `negate = <Boolean>` which when `TRUE` does an inverse search of the pattern along the string.

    ```
    str_*(<string>, <pattern>, <replacement>|<negate>)
    ```

## Extract sub-string

What lineages do our ammonia and nitrite oxidisers come from? We can inspect their assignment at various taxonomic levels to find out.

!!! r-project "code"    

    ```r
    # Extract domain-level assignments
    str_extract(nitros, "d__[^;]+") %>%
      unique()

    # Extract phylum-level assignments
    str_replace(nitros, ".+p__([^;]+);.+", "Phylum: \\1") %>%
      unique()
    ```

    > ```
    > [1] "d__Bacteria" "d__Archaea"
    > 
    > [1] "Phylum: Nitrospirota"   "Phylum: Proteobacteria" "Phylum: Crenarchaeota"  "Phylum: Nitrospinota"  
    > [5] "Phylum: Zixibacteria"  
    > ```

Here we used two different ways of getting sub-strings out of long strings. 

1. `str_extract()` searches the `nitros` vector for cases of `d__` followed by anything that is NOT a ";" (`[^;]`) more than once (`+`). Note that the taxonomic levels are delineated using a semicolon. When it finds a match to a semicolon, it will stop and return the resulting sub-string. The text below illustrates the pattern matching where `+` represents "still matching" and `!` represents "not a match".
```
string:     d__Bacteria; p__Nitrospirota; c__Nitrospiria; o__Nitrospirales; f__Nitrospiraceae; g__Nitrospira; s__uncultured_Cytophaga
extract:    d__[^;]++++!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
```
2. `str_replace` looks at everything `.+` before `p__` then captures the pattern "anything except a semicolon more than once" `[^;]+`. This captured pattern ends with a semicolon and everything else in the string *et cetera*. We replace the pattern with `Phylum: ` then the captured pattern represented in regex by `\\1` (meaning captured pattern 1). The text below illustrates the matched string, where "everything else" is represented using `*`.
```
string:     d__Bacteria; p__Nitrospirota; c__Nitrospiria; o__Nitrospirales; f__Nitrospiraceae; g__Nitrospira; s__uncultured_Cytophaga
match:      *************p__[^;]++++++++;********************************************************************************************
capture:    !!!!!!!!!!!!!!!!Nitrospirota!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
```

Lets attempt to capture more than one pattern:

!!! r-project "code"

    ```r
    # Extract phylum and genus level assignments and sort unique outputs
    str_replace(nitros, ".+p__([^;]+);.+g__([^;]+).*", "Phylum: \\1, Genus: \\2") %>% 
      unique() %>% 
      str_sort()
    ```

    > ```
    >  [1] "d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Nitrococcales; f__Nitrococcaceae"    
    >  [2] "d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Nitrosococcales; f__Nitrosococcaceae"
    >  [3] "Phylum: Crenarchaeota, Genus: Candidatus_Nitrosopelagicus"                                      
    >  [4] "Phylum: Crenarchaeota, Genus: Candidatus_Nitrosopumilus"                                        
    >  [5] "Phylum: Crenarchaeota, Genus: Nitrosopumilaceae"                                                
    >  [6] "Phylum: Nitrospinota, Genus: P9X2b3D02"                                                         
    >  [7] "Phylum: Nitrospirota, Genus: 4-29-1"                                                            
    >  [8] "Phylum: Nitrospirota, Genus: Nitrospira"                                                        
    >  [9] "Phylum: Nitrospirota, Genus: uncultured"                                                        
    > [10] "Phylum: Proteobacteria, Genus: 3PJM14"                                                          
    > [11] "Phylum: Proteobacteria, Genus: AqS1"                                                            
    > [12] "Phylum: Proteobacteria, Genus: Cm1-21"                                                          
    > [13] "Phylum: Proteobacteria, Genus: FS142-36B-02"                                                    
    > [14] "Phylum: Proteobacteria, Genus: IS-44"                                                           
    > [15] "Phylum: Proteobacteria, Genus: MSB-1D1"                                                         
    > [16] "Phylum: Proteobacteria, Genus: Nitrosomonas"                                                    
    > [17] "Phylum: Proteobacteria, Genus: SZB85"                                                           
    > [18] "Phylum: Zixibacteria, Genus: Zixibacteria"
    > ```

Let's break a few items down:

1. We are now capturing two patterns: `\\1` represents the phylum name, and `\\2` represents the genus name. The numbers represent the order of the captured pattern that occurs in the string.
2. Some of it did not work, resulting in the entire string being printed out (the default behaviour in many of the stringr functions, better safe than sorry!)

??? question "How would you fix the issue in point 2?"

    Prior to `str_replace()`, add a `str_subset()` and use the genus prefix `g__` to retain all taxonomies with valid genera assignments.

    !!! r-project "code"

        ```r
        str_subset(nitros, "g__") %>% 
          str_replace(".+p__([^;]+);.+g__([^;]+).*", "Phylum: \\1, Genus: \\2") %>% 
          unique() %>% 
          str_sort()
        ```

Notice the subtle change in the regex from `.+` to `.*` at the end of the pattern? The combination `.+` means "anything more than **once**", whereas `.*` means "anything more than **zero times**". Most of the time, either pattern will create the desired output. However, in this example, the result will look strange if `+` was used instead of `*`. Try it to see for yourself what the difference is.

## Detecting and counting patterns

How many of these lineages are putative ammonia oxidisers (i.e., "Nitroso-")? Lets count them:

!!! r-project "code"

    ```r
    str_detect(nitros, "Nitroso") %>%
      sum()
    ```

    > ```
    > [1] 75
    > ```

If we only run the `str_detect()` part, it will return a Boolean logical vector which `sum()` uses to tally up the number of `TRUE` elements. 

!!! question "How would you count the number of lineages for putative nitrite, but not ammonia, oxidisers?"

    Remember that putative nitrite oxidisers carry the "Nitro-" prefix.

    ??? success "Solution"

        Given that the entirety of `nitros` contains sequence variants that have `"Nitro"` somewhere along it's assigned lineage, we need only count those that **do not** contain `"Nitroso"`.

        !!! r-project "code"

            ```r
            str_detect(nitros, "Nitroso", negate = TRUE) %>%
              sum()
            ```

Lets ask a different question:

> How often does the prefix Nitroso- occur along the taxonomic lineage?

Here, we are interested in the substring frequency along each element across the vector. The difference between this and the previous question is subtle. The code below can help illuminate the distinction.

!!! r-project "code"

    ```r
    str_count(nitros, "Nitroso")
    ```

    > ```
    >  [1] 0 2 4 2 2 2 0 2 4 2 2 0 2 4 4 0 2 4 0 0 2 0 0 4 0 0 2 0 0 0 2 4 2 1 4 2 4 1 4 4 1 4 2 0 5 2 0 0 2 1 2 0 0 0 0
    > [56] 2 0 2 0 2 2 2 2 4 4 4 0 4 0 4 2 4 2 4 0 4 2 0 4 0 1 4 4 4 2 0 4 4 2 2 0 4 2 1 2 0 2 2 2 2 0 2 2 0 2 4 44
    > ```

To summarise:

* `str_detect() %>% sum()` tallies the number of elements that contain a pattern. A Boolean vector is returned by `str_detect()`, and then `TRUE` statements are tallied by `sum()`.
* `str_count()` tallies the number of times a pattern is observed in an element. A numeric vector is returned.

## Tap tap... Is this working?

How do you know if the search pattern worked? In other words, did the search pattern target the intended sub-strings? Conversely, *did it also target sub-strings we did not intend to capture*? When starting out in learning regular expressions, it is useful to visually inspect what the pattern supplied is matching to. Here, we will use `str_view()` to do "unit tests" on strings to check our patterns.

In the previous section, we extracted and printed phylum-genera pairs from the `nitros` vector. Notice that there are genera with odd code-like name (e.g., P9X2b3D02, Cm1-21)? How would we construct a regex that can be used to count the number of named genera we have in `tax$Taxon`? Before exploring the logic required to construct this regex, lets create a smaller vector of unique genus assignments. It is easier to build up a regex by working on a smaller problem.

!!! r-project "code"

    ```r
    genera <- str_extract(tax$Taxon, "g__[^;]+") %>%
      unique()
    ```

Now lets work through the logic:

??? question "What differentiates named genera from code-name genera?"

    Named genera are words in a linguistic sense. They are also "names" where they start with an upper-case letter followed by a string of lower-case letters. Notice that there are no non-alphabet characters in them.

Using our logic, we can construct this pattern `[A-Z][a-z]+` which means "any capital letter from A to Z next to any lower case letters from a to z more than once". Lets check how the pattern did:

!!! r-project "code"

    ```r
    # Named genera starts with an upper-case letter, followed by multiple lower-case letters
    str_view(genera, "[A-Z][a-z]+")

    # And the tail
    str_view(genera, "[A-Z][a-z]+") %>% tail()
    ```

    > ```
    >  [1] │ g__<Chloroplast>
    >  [2] │ g__<Woeseia>
    >  [3] │ g__<Mitochondria>
    >  [4] │ g__<Sva>1033
    >  [7] │ g__<Parahaliea>
    >  [8] │ g__<Actibacter>
    >  [9] │ g__<Lutimonas>
    > [10] │ g__<Robiginitalea>
    > [11] │ g__<Anaerosolibacter>
    > [13] │ g__<Aquibacter>
    > [14] │ g__<Pseudophaeobacter>
    > [15] │ g__<Flavirhabdus>
    > [16] │ g__<Lutibacter>
    > [17] │ g__<Candidatus>_<Fritschea>
    > [18] │ g__<Sva>0081_sediment_group
    > [19] │ g__<Halioglobus>
    > [20] │ g__<Fusibacter>
    > [21] │ g__<Erythrobacter>
    > [22] │ g__<Limibacillus>
    > [23] │ g__<Crassaminicella>
    > ... and 213 more
    > ```

    > ```
    > [281] │ g__<Gven>-F17
    > [282] │ g__<Gaetbulibacter>
    > [283] │ g__<Sneathiella>
    > [285] │ g__<Thermomarinilinea>
    > [286] │ g__<Dadabacteriales>
    > [287] │ g__<Colwellia>
    > [288] │ g__<Gemmatimonadaceae>
    > [289] │ g__<Bacteroidetes>_vadinHA17
    > [290] │ g__<Dechloromonas>
    > [291] │ g__<Vicinamibacteraceae>
    > [292] │ g__<Desulfobulbus>
    > [293] │ g__<Pelagicoccus>
    > [296] │ g__<Pirellula>
    > [297] │ g__<Hyphomicrobium>
    > [298] │ g__<Spirochaeta>_2
    > [299] │ g__[<Desulfobacterium>]_catecholicum_group
    > [301] │ g__<Porticoccus>
    > [303] │ g__<Iodidimonas>
    > [306] │ g__<Oceanibulbus>
    > [307] │ g__<Carboxylicivirga>
    > ```

Notice how `str_view()` differentiates matches from non-matches using different colours and envelopes them in `<match>`. This is how it can help us build the intuition for using regex. 

Our pattern looks good, but there are a few unintended matches as well:

* Some have numbers suffixed immediately after the name-like genera or following a `-` or `_`
* One is encased in square brackets (`g__[Desulfobacterium]_catecholicum_group`)

We will refine our pattern by incorporating the fact that named genera must end with a lower-case letter:

!!! r-project "code"

    ```r
    str_view(genera, "[A-Z][a-z]+$")
    str_view(genera, "[A-Z][a-z]+$") %>% tail()
    ```

    > ```
    >  [1] │ g__<Chloroplast>
    >  [2] │ g__<Woeseia>
    >  [3] │ g__<Mitochondria>
    >  [7] │ g__<Parahaliea>
    >  [8] │ g__<Actibacter>
    >  [9] │ g__<Lutimonas>
    > [10] │ g__<Robiginitalea>
    > [11] │ g__<Anaerosolibacter>
    > [13] │ g__<Aquibacter>
    > [14] │ g__<Pseudophaeobacter>
    > [15] │ g__<Flavirhabdus>
    > [16] │ g__<Lutibacter>
    > [17] │ g__Candidatus_<Fritschea>
    > [19] │ g__<Halioglobus>
    > [20] │ g__<Fusibacter>
    > [21] │ g__<Erythrobacter>
    > [22] │ g__<Limibacillus>
    > [23] │ g__<Crassaminicella>
    > [24] │ g__<Ulvibacter>
    > [25] │ g__<Gracilimonas>
    > ... and 174 more
    > ```

    > ```
    > [296] │ g__<Pirellula>
    > [297] │ g__<Hyphomicrobium>
    > [301] │ g__<Porticoccus>
    > [303] │ g__<Iodidimonas>
    > [306] │ g__<Oceanibulbus>
    > [307] │ g__<Carboxylicivirga>
    > ```

That looks much better! Notice also we have managed to capture Candidatus genera because our pattern matches the proposed name. This is okay as they will be on their way to being named sometime in the future. Lets now use this to count the number of named genera overall:

!!! r-project "code"

    ```r
    str_extract(tax$Taxon, "g__[^;]+") %>% 
      str_detect("[A-Z][a-z]+$") %>% 
      sum(na.rm = TRUE)
    ```

    > ```
    > [1] 1490
    > ```

    The `na.rm = TRUE` argument is necessary as there is an `NA` generated by the code that created `genera`. This is from lineages that did not have valid genus-level assignments.

In summary, the code above extracted the genus-level assignments from the long lineage string, detected which of them were named, then counted those while ignoring `NA`s.
-->
