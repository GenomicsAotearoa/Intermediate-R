# Functions and conditional statements

!!! note "Learning objectives"

    - Identify parts of a function
    - Write custom functions
    - Use conditional statements to control outputs
    - Refine functions to improve efficiency
    - Access function source code from other packages

## Anatomy of functions

It's not a secret that for as long you've used R, you've been using functions. Here, we're going to make them! Functions are, like all things in R, a type of object (implications discussed in a [later episode](./5.data_structures.md#recursive-objects-functions)). They are the "verbs" of the R programming language where, instead of storing data, functions store code that defines how it behaves and operates on other objects.

In an R script, functions are created and assigned using the following syntax:

```r
f <- function(<arguments>) {

  <do_something>

}
```

Lets break down the anatomy of the pseudocode:

- `f` is the assigned name of the function.
- `function()` initialises a function call, telling R that
    - We are writing a function
    - Anything inside round brackets are arguments for the function
    - Anything after the closing round bracket and on the same line is the code that defines the function
- `{   <do_something>   }` is the expression that defines how the function works

Let's write a function to give some context as to what each part does.

$$
f(x) = \sqrt{2(x + 1)}
$$

The above is an equation for a function called $f$ that takes a value $x$ as input and outputs a value based on $x$. We can translate that into R code:

!!! r-project "code"

    ```r linenums="1"
    f1 <- function(x) {
      sqrt(2 * (x + 1))
    }
    ```

Here, we've "wrapped" an arithmetic operation in a function.

!!! tip "Alternative syntax"

    We can also use a shorthand for the `function()` call by replacing `function` with a `\`:

    !!! r-project "code"

        ```r
        f1 <- \(x) sqrt(2 * (x + 1))
        ```

    This syntax is useful for on-the-fly functions that can be applied [using `map()` functions](#iterations).

    Notice also that the function expression is on the same line as the function call. This syntax is acceptable for short expressions but not encouraged for longer ones.

!!! tip "Infix functions"

    Most objects we think of as functions are ***prefix*** functions, where arguments are placed after the function call. However, there are also ***infix*** functions, where arguments are placed on either side of the function call. For example:

    !!! r-project "code"

        ```r
        x <- 2 + 3
        ```

    Both `<-` and `+` are infix functions for assignment and addition, respectively. All basic arithmetic (e.g., `+`, `-`, `*`, and `/`), assignment (including `=`), logical (e.g., `|`, `&`, `&&`, etc.), and relational (e.g., `>`, `!=`, `==`, etc.) operators are primitive (i.e., foundational part of the language) infix functions.

    The pipe operator `%>%` introduced by the `magrittr` package is a user-generated infix function. As this is a custom infix function, the `%` that surrounds the operator is necessary. It does not have to be a symbol or operator and can be represented by anything really, (e.g., `%in%`) even [emojis](https://colinfay.me/playing-r-infix-functions/)!

    We can define our own infix function:

    !!! r-project "code"

        ```r linenums="1"
        `%<I>%` <- function(lhs, rhs) {
          # Get the minima from the left hand side and the maxima from the right hand side
          c(min(lhs), max(rhs))
        }

        rnorm(10) %<I>% rnorm(200)
        ```

## Control flow 1: Conditional execution

We will take a little detour from functions to learn about control flow. These are constructs that code for ***decision making*** (this episode) and ***repetition*** (next episode). Decision making/conditional execution helps to direct the "flow" of operations using Boolean logic (`TRUE`/`FALSE`). In R, conditional execution is coded using `if-else` statments:

```r linenums="1"
if (<predicate>) {

  <expression_1>

} else {

  <expression_2>

}
```

The pseudocode above means `if` the `<predicate>` is (or returns a) `TRUE`, execute `<expression_1>`, otherwise execute `<expression_2>`.

For example:

!!! r-project "code"

    ```r linenums="1"
    if (x < 10) {
      print("x is less than 10")
    } else {
      print("x is more than 10")
    }
    ```

!!! note "Predicate and predicate functions"

    A predicate is a statement or function that evaluats and returns **one** `TRUE` or `FALSE` value. For example, this is a predicate that evaluates if `x` is larger than 5:
    
    ```r
    x > 5
    ```

    If we set `x <- 10`, the code will return a `TRUE`.

    R has many built-in predicate functions (i.e., functions that evaluate a statement or object and returns a `TRUE`/`FALSE`). They are often prefixed using `is.<something>()`. For example:

    !!! r-project "code"

        ```r
        x <- 9
        tim <- "Tim is eating"
        y <- 1:6

        # Predicate function
        is.character(x)
        is.character(tim)
        is.character(y)
        is.numeric(y)
        ```

    Notice that regardless of the length of the vector, the predicate functions return only one Boolean variable. This is important for conditional statements as it can only evaluate predicates and not a vector of Boolean variables.

The `else` statement is optional (and often unnecessary). The expression will not be evaluated if the predicate returns `FALSE`.

!!! r-project "code"

    ```r linenums="1"
    # Predicate returns TRUE, expression is evaluated
    if (x < 10) {
      print("x is less than 10")
    }

    # Predicate returns FALSE, expression is not evaluated
    if (x > 10) {
      print("x is greater than 10")
    }
    ```

For complex predicate evaluations (e.g., intermediate thresholds) or evaluations that lead to different paths (e.g., hierarchical decision making), we can chain and/or nest multiple statments together:

```r
if (<predicate_1>) {
  
  <expression_1>

} else if (<predicate_2>) { # Chained statements: an if-else after an if-else
  
  if (<predicate_2a>) { # Nested statements: an if-else inside and if-else
    
    <expression_2a>
  
  } else {
    
    <expression_2b>
  
  }

} else {
  
  <expression_3>

}
```

### Vectorised conditional execution

The above conditional statements only operate when there is only one Boolean value. What if we wanted to generate different outcomes depending on the elements in a vector? In this case, we can use these two functions depending on how many outcomes we need:

=== "Binary outcomes" 
    
    If we needed one outcome each for `TRUE` or `FALSE`, we can use `if_else()`, a vectorised if-else statement that evaluates a Boolean vector (or a condition that returns one) and produces outcomes depending on whether each element is a TRUE or FALSE. For example:

    !!! r-project "code"

        ```r linenums="1"
        fridge <- c("banana", "apple", "kale", "durian", "pear", "spinach")

        if_else(
          fridge %in% fruit,
          str_c(str_to_upper(fridge), " is a fruit"),
          str_c(fridge, " is not a fruit")
        )
        ```

    !!! tip "Base R equivalent: `ifelse()`" 

        Base R also has a similar implementation: `ifelse()`. However, `dplyr::if_else()` strictly preserves the data type (e.g., the output will not be coerced to a character if the input is a factor) and can evaluate missing values; `base::ifelse()` does not enforce data type preservation and returns missing values when it encounters them.

=== "Multiple conditions and outcomes" 

    If we required different outcomes based on multiple, hierarchical conditions, we can use `case_when()`, a general vectorised if-else analogous to chained if-else statements. For example:

    !!! r-project "code"

        ```r linenums="1"
        fridge <- c("cheese", fridge, "milk")
        dairy <- c("cheese", "yoghurt", "butter", "milk")
        vegetable <- c("beetroot", "beans", "kale")

        case_when(
          fridge %in% fruit ~ str_c(fridge, " is a fruit"),
          fridge %in% vegetable ~ str_c(fridge, " is a vegetable"),
          fridge %in% dairy ~ str_c(fridge, " is a dairy product"),
          .default = str_glue("You don't even like {fridge}!")
        )
        ```

## Alpha diversity

Time to apply all of the above to write a function! For this section, we will be writing a function that calculates the $\alpha$-diversity (a measure local diversity) of a sample. The simplest measure is richness (often denoted $q$ or $S$), which represents the *number of species/taxonomic units*. While richness is simple and intuitive to understand, it is heavily biased by rare members of the sample community. This is always the case with microbiome data. Other $\alpha$-diversity indices were constructed to account for the uneven distribution of taxonomic units by incorporating relative abundance information. Popular options are:

**Shannon's index,** $H$

$$
H = -\sum_{i=1}^{q} p_{i} \log p_{i}
$$

Where $p_{i}$ is the proportion (or relative frequency) of the $i^{th}$ organism relative to the sample total.

**Simpson's diversity,** $D$

$$
D = \frac{1}{\lambda}
$$

Where the $\lambda$ is Simpson's concentration index, defined as

$$
\lambda = \sum_{i=1}^{q} p_{i}^2
$$

For the mathematically inclined, you might observe that these indices:

- Gives more weight to abundant taxa ($D$ moreso than $H$)
- Reach their maxima when all taxa are exactly evenly distributed in the sample
- Reach their minima when one taxa that dominate
- Are not on the same scale ($H$ is on a log scale, $q$ and $D$ are on the "number of taxonomic units" scale)

For now, it is enough to know that they are mathematical formulas that we are going to translate into code.

### Starting small: richness

We will start by writing a function to calculate richness (the number of taxonomic units in the sample). Applied in R, this means the number of non-zero elements in a numeric vector.

!!! r-project "code"

    ```r linenums="1"
    # Test vector
    test_vector <- asv$AS1A3

    # Richness
    calc_alpha_diversity <- function(x) {
      sum(x > 0)
    }

    # Test function
    calc_alpha_diversity(test_vector)
    ```

### Adding arguments: Shannon's and Simpsons's diversity

Next, lets add the other indices to be part of the function. We will use conditional execution to control output depending on the index is requested.

!!! r-project "code"

    ```r linenums="1"
    calc_alpha_diversity <- function(x, index) {
    
      # Richness
      q <- sum(x > 0)

      # Shannon's index
      p <- x / sum(x)
      H <- - sum(p * log(p))

      # Simpson's diversity
      p <- x / sum(x)
      D <- 1 / sum(p ^ 2)

      if (index == "richness") {
        return(q)
      } else if (index == "shannon") {
        return(H)
      } else if (index == "simpson") {
        return(D)
      }

    }

    # Test that it works
    calc_alpha_diversity(test_vector, index = "richness")
    calc_alpha_diversity(test_vector, index = "shannon")
    calc_alpha_diversity(test_vector, index = "simpson")
    ```

Here, we're calculating all possible outcomes, then returning values based on the index requested.

!!! tip "`return()`"

    The `return()` function returns/outputs the value specified in it and stops evaluation of any code below it. In `calc_alpha_diversity()`, if the index requested is richness, and subsequent code to calculate the other indices are not evaluated. In the case where a function code has no `return()`, the function will output the last evaluation.

The function we wrote works for $q$ and $D$, but not for $H$. Lets revise that.

### Troubleshooting and refining code :wrench:

Lets troubleshoot our function first. Why did the code not work for Shannon's index?

!!! warning "A little math"

    `log(0)` is undefined. However, in R, it is given the value `-Inf` for bases \> 0 and `Inf` for bases \< 0. If any `p` is 0, the operation `0 * log(0)` will return `NaN` (Not a Number). Therefore, the summation of that will return `NA`.

We will also consider other areas for refinement:

=== "Repeatedly assigning `p`"

    Relative frequency `p` is not required for richness calculations and is shared for calculations of Shannon's and Simpson's indices.

=== "Assigning `H` and `D`"

    Assigning of $H$ and $D$ helps us, the human, to differentiate the indices in mathematical notation. However, R does not care which name is used. The decision to return either index is already managed by conditional statements.

=== "Chained if-else"

    Chained statements are not necessary here. Conditional execution (and `return()`) should occur earlier to prevent unnecessary code evaluation.

=== "Choice of logarithm base"

    Some people may have a reason to use another base for the `log()` function used in calculating Shannon's index. While the natural logarithm (log in base $e$) is often the default choice, there should be an option to change that if desired. To set a default value in a custom function, add the desired value to the argument within the function call (see below).

With that, lets revise the function:

!!! r-project "code"

    ```r linenums="1"
    calc_alpha_diversity <- function(
      x, index, 
      log.base = exp(1) # Provide natural logarithm as default
    ) {
    
      # Richness
      if (index == "richness") {
        return(sum(x > 0))
      }

      # Relative frequency
      p <- x / sum(x)

      # Shannon's index
      if (index == "shannon") {
        H <- - sum(p * log(p, base = log.base), # Provide option for changing log base
                   na.rm = TRUE)                # Removes NA prior to summation
      }

      if (index == "simpson") {
        H <- 1 / sum(p ^ 2)
      }

      H

    }

    # Test the function
    calc_alpha_diversity(test_vector, index = "richness")
    calc_alpha_diversity(test_vector, index = "shannon")
    calc_alpha_diversity(test_vector, index = "simpson")
    ```

It works! Note that without a return, the function simply outputs the last evaluted code (in this case, this is the value `H`).

### Defending our function :shield:

What would happen if we used our functions with non-ideal inputs? For this, we will take hints from the concepts in **defensive programming**. Defensive programming is more about design choices than cybersecurity, where we approach designing code that:

- Has predictable outputs, regardless of inputs
- "Fails fast", thus saving time and computational resources
- Reads well, so others can audit the code and understand what each line is doing

Can you identify some scenarios where our function might not do so well?

??? warning "Pitfalls and food for thought"

    === "Missing values"

        **What does `NA` mean?**

        Lets consider how these tables were constructed. They were originally sequences that were processed by a software and then reads were counted for each taxonomic unit. If a taxonomic unit was not found in a particular sample read file, the software would have returned a 0. Therefore, `NA` could not have arisen from processing this particular batch.

        However, we can imagine a scenario where `NA` could be introduced from a joining step during data cleaning or pre-processing. This can happen when processing samples by batches.

        Critically, regardless of the reasons for missingness, is a missing count functionally equivalent to 0?

        **What is the effect of `NA`?**

        We used `sum()` quite often in the code. Furthermore, we even added `na.rm = TRUE` in the expression used to calculate Shannon's index to account for the `NA` introduced when evaluating $0 \log 0$. Would we handle `NA` in all parts where `sum()` is used in this way?

    === "Negative numbers"

        **Do negative numbers make sense?**

        Remember that this is a table of counts. What do negative numbers mean in that context? Does it make sense?

        **How does the function handle negative numbers?**

        $q$ would ignore negative numbers. If the negative counts were an oversight or accidental, it would result in an undercount of richness.

        $H$ would not produce a numeric output (the log of a negative number is undefined).

        $D$ would be an underestimate (the sum would be an undercount of the whole).

    === "Non-numeric data"

        **Does non-numeric data make sense for this function?**

        These indices are meant for count data (i.e., numeric data). Suppose that human error led to the mis-typing of inputs, would we want to coerce the data into numeric type using `as.numeric()`? Are we guessing the intentions and errors of the user? Coercing characters that are not numbers will cause `as.numeric()` to return `NA`.

        **Is it fit for purpose?**

        We established that the function is meant to provide information only on numeric data. Albeit being a small function that runs quickly, we can imagine a scenario where we might either (1) write a function that has many complex steps or (2) run a substantially larger data set through the diversity function. In either scenario, would we want to spend time and computational resources on non-target inputs?

Let's test our function through these non-ideal scenarios. Create vectors with non-ideal properties and try them on the current version of the function.

!!! r-project "code"

    ```r linenums="1"
    # Randomly introduce NA
    test_missing <- test_vector
    test_missing[sample.int(length(test_missing), 5)] <- NA

    # Randomly introduce negative numbers
    test_negative <- ifelse(
      test_vector > 0 & runif(length(test_vector)) > 0.95,
      -test_vector, test_vector
    )

    # Coerce to character
    test_character <- as.character(test_vector)
    ```

!!! tip "Random replacements"

    The code above uses two ways to generate replacements at random. In line 3, a random sampler `sample.int()` was used to indicate 5 random indices to which we wanted to inject `NA`. In lines 6-9, a conditional statement was constructed to replace positive, non-zero values, picked based on a numeric (double) vector picked from a uniform distribution, with negative equivalents.

With those pitfalls in mind, we will need to make some design decisions and implement them in code. Here are my choices:

=== "Remove missing values"
  
    Functionally, they are the same as not observing a taxa in a sample (equivalent to 0). *Warn* the user when this happens but continue with evaluating input.

=== "*Error* on negative numbers and non-numeric data"

    These data types are not intended for use with diversity indices here. Lets not spend computing time and resources on them. To achieve this, we will "error out" of the function where if negative numbers and non-numeric data are encountered, the function will stop further computation and produce an error message.

Feel free to implement your own design choices by modifying the code below!

!!! r-project "code"

    ```r linenums="1"
    calc_alpha_diversity <- function(
      x, index, 
      log.base = exp(1) # Natural logarithm as default
    ) {
    
      # Warn for missing values
      if (anyNA(x)) {
        warning("x contains NAs which are removed prior to calculations.")
        x <- x[!is.na(x)]
      }

      # Error on non-numeric and negative data
      if (!is.numeric(x) | any(x < 0)) {
        stop("x must be positive numeric values!")
      }

      # Richness
      if (index == "richness") {
        return(sum(x > 0))
      }

      # Relative frequency
      p <- x / sum(x)

      # Shannon's index
      if (index == "shannon") {
        H <- - sum(p * log(p, base = log.base), # Provide option for changing log base
                   na.rm = TRUE)                # Removes NA from 0 * log(0)
      }

      if (index == "simpson") {
        H <- 1 / sum(p ^ 2)
      }

      H

    }
    ```

Try the new function on the test vectors:

!!! r-project "code"

    ```r linenums="1"
    calc_alpha_diversity(test_missing, index = "shannon")
    calc_alpha_diversity(test_negative, index = "simpson")
    calc_alpha_diversity(test_character, index = "richness")
    ```

<!-- 
Could add a sub-section on recursive functions using a limited integral or factorial as an example. 
-->

## Improve function design

### Read other functions

One of the best ways to improve how we write functions is to read other people's functions! Not only do we get to see how others design their functions, we can also learn new and useful functions along the way!

We can access the source code of a function using `getAnywhere()`:

!!! r-project "code"

    ```r
    getAnywhere(lm)
    ```

Some functions may not have directly accessible source code. For example:

!!! r-project "code"

    ```r
    getAnywhere(anova)
    ```

Notice that the body of the function consists only of `UseMethod("anova")`. This is because `anova()` can take many different kinds of inputs and run different code depending on the input (i.e., it has different `methods()` for the same function). We can see what those methods are and inspect the source code for any of them:

!!! r-project "code"

    ```r
    # What methods are available for anova?
    methods(anova)

    # Inspect anova.lm
    getAnywhere(anova.lm)
    ```

In some cases, a function could have the same name but are implemented differently because they are part of a different package. For example:

!!! r-project "code"

    ```r
    getAnywhere(filter)
    ```

To access the `filter()` source code from the `stats` package, we need pick one by its index:

!!! r-project "code"

    ```r
    # Get source code for filter in stats package
    getAnywhere(filter)[2]
    ```

### `return()` early

Use `return()` early in the source code especially if other arguments will lead to more time consuming evaluations. This prevents wasteful use of time and resources to compute variables that will not even be used as outputs!

### `switch()` evaluations depending on argument input

`swtich()` is a useful function that evaluates different expressions depending on the argument inputs. It can also be given a default output when no arguments match those specified which can be coded to output a warning or message.

!!! r-project "code" 

    ```r linenums="1"
    calc_alpha_diversity <- function(x, index, log.base = exp(1)) {
    
      # Warn for missing values
      if (anyNA(x)) {
        warning("x contains NAs which are removed prior to calculations.")
        x <- x[!is.na(x)]
      }

      # Error on non-numeric and negative data
      if (!is.numeric(x) | any(x < 0)) {
        stop("x must be positive numeric values!")
      }

      # Richness
      if (index == "richness") {
        return(sum(x > 0))
      }

      # Relative frequency
      p <- x / sum(x)

      # Indices
      switch(
        index, # Value to be matched against in the list below
        shannon = - sum(p * log(p, base = log.base), na.rm = TRUE),
        simpson = 1 / sum(p ^ 2),
        warning("Unknown index. Should be one of 'richness', 'shannon', or 'simpson'.") # Default output if unmatched
      )

    }
    ```

### Think of the users

*Who is the target user for your functions?*

If it's just you, do whatever you want! However, the fact that you are assigning code to functions implies that you probably want to reuse it for other things/projects or even share them with your colleagues/the world!

If you intend to share your functions with other people/computers/robots, it is important to think about dependencies. Other people will have different set-ups. Thus, it is advisable to write functions using other functions in base R. If you must use other packages, make sure to advise and install early in the script.

While we write functions to be as predictable, elegant, and concise as possible, there are situations where we want to add flexibility. Keep in mind that flexible functions often involve more code. To achieve this, we can write functions that call other custom functions. This is called modularisation. Modular code also helps with troubleshooting, readability, and benchmarking as pieces of it can be tested. This is especially important for production-level code.

*What stage are you at?*

Assuming you are writing functions for your analyses, the syntax of your functions are likely geared towards your specific needs at a particular given stage. At the exploratory analysis stage, functions are written with flexbility in mind, perhaps even a little messy or less efficient that it could be.

As you progress to production level code and/or need to use complex processes (permutation tests, sub-sampling, Bayesian methods, etc.), you're likely going to need to think about:

:white_check_mark: **Code safety**
Predictable and non-redundant inputs and outpus, and preventing *ad inifinitum* runs

:white_check_mark: **Efficiency**
Use benchmarked algorithms, reduce/remove side effects, parallel processing, reduce overheads

:white_check_mark: **Troubleshooting**
Informative errors and warnings, modularised functions

:white_check_mark: **Readability**
Commented code, verbose syntax, appropriate assignments (as opposed to long piped processes)

### Break your own code!

The best way to learn from your own functions? Break them! How would it handle nonsensical inputs? What are its limits? How much data is too much data? Is it taking seconds, minutes, days to run? We can learn so much about how the function (and R in general) works when we stress test them.

<!--

## I can make those?!

Functions are integral components of R. They are what make it possible to do, well, everything! Even addition `+` is a function: 

!!! r-project "code"

    ```r
    mode(`+`)
    str(`+`)
    ```

    > ```
    > [1] "function"
    > function (e1, e2)
    > ```

Like all things in R, a function is also an object (we'll see what other implications that has later). Think of functions as verbs. They are pieces of code that do something and produce an outcome (sometimes invisibly). Just as you can assign an object to a variable, you can assign entire chunks of code that "does something" to a object. In R, that is what a function is: an object that does something. So yes, you can write functions! 

In this lesson, we will learn to construct custom functions and conditional statements. Conditional statements are code chunks that helps us handle decision making according to rules. Then, we will write a custom function that calculates different alpha diversity metrics (a staple in any ecological analysis). As part of writing the custom function, we will learn a little bit about defensive programming and how that provides a practical foundation for writing resilient and reliable functions.

## Anatomy of a function

Here is a pseudocode representation of assigning a function:

```r
my_function <- function(<arguments>) {

  <do something>

}
```

All functions start with the `function` call, followed by arguments enveloped between parentheses, and finally the expression (the `<do something>` part of the pseudocode above). This defines what the function does. The expression need not be wrapped in curly brackets `{}` so long as it is on the same line as the `function` call. However, for long expressions, this makes code more legible such that the reader understands that the lines of code wrapped in `{...}` are part of the function object. Here is an example of a function that does $\sqrt{2(x + 1)}$:

!!! r-project "code"

    ```r
    f1 <- function(x) sqrt(2 * (x + 1))

    f1(x = 3)
    ```

    > ```
    > [1] 2.828427
    > ```

!!! tip "`function` shorthand"

    The `function` call can also be shortened to just a backslash `\` to mean the same thing. For example, this is equivalent to the code above:

    !!! r-project "code"

        ```r
        f1 <- \(x) sqrt(2 * (x + 1))
        ```
    
    This makes it easier to write short functions on the fly for interactive use.

**Default values**

Many pre-built functions that we use on a day-to-day basis takes one argument as user input. However, this is usually a convenience. For example:

!!! r-project "code"

    ```r
    log(5)
    ```

    > ```
    > [1] 1.609438
    > ```

By default, the `log()` function returns the natural log (base $e$). If we access its help page, we find that we can specify another base for the logarithm conversion.

!!! r-project "code"

    ```r
    log(5, base = 5)
    ```

    > ```
    > [1] 1
    > ```

To set default values for our custom functions, we need only place the value when configuring the arguments. The following function cubes `x` by default, but can take other values to exponentiate `x`.

!!! r-project "code"

    ```r
    f2 <- function(x, p = 3) x ^ p
    f2(3)
    f2(3, p = 5)
    ```

    > ```
    > [1] 27
    > [1] 243
    > ```

## Conditional execution

Before continuing on our journey to write functions, we need to take a brief look at conditional statements. These are common across all programming languages; you may know them as `if-else` statements. They are important constructs that control the flow of operations at all levels, be it within a function or a script, and even across scripts. In their most fundamental form, they resemble this:

```r
if (<predicate>) {

  <expression_1>

} else {

  <expression_2>

}
```

The code above means:

> If the predicate returns a TRUE, run code defined by `<expression_1>`, else run `<expression_2>`.

??? note "Predicate and predicate functions"

    A predicate is a statement or function that evaluation that returns **a single** `TRUE` or `FALSE`. For example, this is a predicate that evaluates if `x` is larger than 5:
    
    ```r
    x > 5
    ```

    If we set `x <- 10`, the code will return a `TRUE`.

    R has many built-in predicate functions (i.e., functions that evaluate a statement or object and returns a `TRUE`/`FALSE`) are often prefixed using `is.<something>()`. For example:

    !!! r-project "code"

        ```r
        x <- 9
        tim <- "Tim is eating"
        y <- 1:6

        # Predicate function
        is.character(x)
        is.character(tim)
        is.character(y)
        is.numeric(y)
        ```

        > ```
        > [1] FALSE
        > [1] TRUE
        > [1] FALSE
        > [1] TRUE
        > ```

    Notice that regardless of the length of the vector, the predicate functions return only one Boolean variable. This is important for conditional statements as it can only evaluate predicates and not a vector of Boolean variables.

To better illustrate what conditional statements do, lets construct an `if...else` to evaluate the following question:

Did we recruit enough reads to perform meaningful ecological analyses?

Let's say that a total read count of at least 500 is required for further analysis and that any value lower than or equal to 500 means we must remedy procedures in handling that sample. Here, our predicate is: `sum(<sample_column>) > 500`. 

!!! r-project "code"

    ```r
    reads_AS1A1 <- sum(asv$AS1A1)

    if (reads_AS1A1 > 500) {
      # If the predicate is TRUE, do this
      print(
        paste("This sample has", reads_AS1A1, "reads.")
      )
      print("It has sufficient reads.")

    } else {
      # If the predicate is FALSE, do this
      print("This sample has insufficient reads.")

    }
    ```

    > ```
    > [1] "This sample has 5610 reads."
    > [1] "It has sufficient reads."
    > ```

### Nested statements

If we had multiple predicates that need to be chained one after another, we can construct nested conditional statements:

```r
if (<predicate>) {
  
  <expression_1>

} else if (<predicate>) {
  
  <expression_2>

} else {

  <expression_3>

}
```

For example:

!!! r-project "code"

    ```r
    reads_S3C3 <- sum(asv$S3C3)
    reads_S3C3

    if (reads_S3C3 > 5000) {
    
      print("Abundant reads")
    
    } else if (reads_S3C3 > 1000 & reads_S3C3 <= 5000) {
    
      print("High number of reads")
    
    } else if (reads_S3C3 > 500 & reads_S3C3 <= 1000) {
    
      print("Sufficient reads")
    
    } else {
    
      print("Insufficient reads")

    }
    ```

    > ```
    > [1] 870
    > [1] "Sufficient reads"
    > ```

When using nested statements, keep in mind that order matters. This means that if the first predicate is `TRUE`, none of the statements below it will be evaluated.

### Vectorised conditional statements

These are functions that: 

1. Takes a vector of Boolean variables (or an expression that produces them)
2. Returns an outcome for each element if it is TRUE
3. Returns another outcome for each element if it FALSE

For binary decisions (i.e., `if (predicate) {...} else {...}`), there are two functions:

* `ifelse()`: part of base R
* `if_else()`: part of `dplyr`

They can both return short, simple variables:

!!! r-project "code"

    ```r
    read_sums <- colSums(asv[, -1])

    ifelse(
      read_sums > 5000, 
      "Sufficient reads", 
      "Insufficient reads"
    ) %>%
      tail()
    ```

    > ```
    >                  AS2C1                  AS2C2                  AS2C3                   S3C1 
    > "Sufficient reads" "Sufficient reads" "Sufficient reads" "Insufficient reads" 
    >                   S3C2                   S3C3 
    > "Insufficient reads"          "Insufficient reads"
    > ```

or return values after evaluating longer expressions:

!!! r-project "code"

    ```r
    if_else(
      read_sums > 1000,
      {
        a <- sqrt(read_sums)
        paste("The square root of this is", a)
      },
      {
        a <- read_sums ^ (1/3)
        paste("The cube root of this is", a)
      }
    ) %>%
      tail()
    ```

    > ```
    >                                         AS2C1                                         AS2C2 
    > "The square root of this is 78.4283112147648" "The square root of this is 75.6174583016383" 
    >                                         AS2C3                                          S3C1 
    > "The square root of this is 82.4075239283404" "The square root of this is 33.5111921602321" 
    >                                          S3C2                                          S3C3 
    > "The square root of this is 60.5061980296234"   "The cube root of this is 9.54640270936004"
    > ```

For nested statements, there is `case_when()` from `dplyr` that takes the form of:

```r
case_when(
  <predicate_1> ~ <expression_1>,
  <predicate_2> ~ <expression_2>,
  <predicate_3> ~ <expression_3>,
  ...
  TRUE ~ <default_value>
)
```

### Practical usage

**`else` is optional**

For most use cases it is sufficient to only construct the `if (<predicate>) {<expression>}` part of the statement. Unless there is a good reason to pick one option over the other, the `else {<expression>}` is optional and can be entirely omitted. This is because R will only execute the expression within the statement if the predicate is `TRUE`. For this reason, it is very common to see the `else {}` omitted in functions.

**Nested statements are rarely a good idea**

Often, nested statements are not helpful. Nested statements can lead to messy code that ends up being illegible and the results can be cryptic (i.e., the reader may not intuitively know where the results come from based on the chain of statements). 

Sometimes you may have a reason to use nested statements. For example, there may be genuine need for a hierarchical way of evaluating the flow of data where some collection of thresholds warrant a different method of processing data downstream. 

An alternative to nested statements is writing multiple functions which are called under different scenarios. This modular structure means that you not only remove potential redundancies, but it also improves code legibility where readers can easily determine the functions that are being called, the expression the function uses, and the intended result.

**Vectorise for one-off use cases**

R is particularly proficient when we use functions that take in vectors. In cases where you need to `mutate()` a column in a data frame (e.g., replacing values based on pattern searches and return a variable), the vectorised `if_else()` and `case_when()` are your friends. Also, I prefer to use `if_else()` as opposed to `ifelse()` as it can handle missing values and produce consistent output types, a coveted feature in ensuring input-output consistency.

## Functions are objects too

!!! note ""

    This section is a little more abstract than previous sections and might take a while to get our heads around. However, it is nonetheless useful to know how functions can behave like objects so that we can use them more flexibly.

At the beginning of this lesson, we came across the concept that functions are objects. In examples above, we assign names to functions in order to call them. That is one property of an object: *they can be named*. However, there are also objects that we use on the fly without naming them. Consider the following:

```r
c("A", "B", "D", "F")
```

If you run the above, it will print out the letters `A`, `B`, `D`, and `F`. We haven't named them, and yet we can use them. The same goes for functions, but the syntax is slightly different:

!!! r-project "code"

    ```r
    (\(x, y) x + y)(x = 3, y = 5)
    ```

    > ```
    > [1] 8
    > ```

We've encased the function itself in brackets `()`, supplied it with the required arguments, and it provides an output. This is known as an **anonymous function**. Keep this in mind as it will be quite prominent in the next lesson.

Another property of objects is that *they can be stored*. While it is not possible to store a function in a vector, it is possible to store them in a list. This is a valid way to store functions:

```r
flist <- list(
  \(x) x + 1,
  \(x) x + 2,
  \(x) x ^ 3
)
flist
```

```
[[1]]
\(x) x + 1

[[2]]
\(x) x + 2

[[3]]
\(x) x ^ 3
```

With this structure, you can iterate through the list and generate different outputs depending on the function applied.

You can also use it as input to another function. For example, if you pass that into `class()` or `mode()`, it will tell you it is a character vector. When you pass a function into `class()`, it will tell you that it is a function (no surprise there).

!!! r-project "code"

    ```r
    class(f1)
    ```

    > ```
    > [1] "function"
    > ```

That reveals another aspect of functions: they can be *treated as input*.

We will learn about iterations in the next lesson, but to showcase the points:

* functions can be stored (thus iterated)
* functions can be treated as input

!!! r-project "code"

    ```r
    map(flist, \(x) x(2))
    ```

    > ```
    > [[1]]
    > [1] 3
    > 
    > [[2]]
    > [1] 4
    > 
    > [[3]]
    > [1] 8
    > ```

!!! note "Recursive functions"

    The last property of an object is that for some types, they can exist inside themselves. Consider a nested list:

    ```r linenums="1"
    nl <- list(1, "a", \(x) x + 4)
    nl <- list(
      nl = list(
        nl = list(
          nl = nl
        )
      )
    )
    ```

    The above is a list object, in it's own list object, it it's own list object, in it's own list object. Phew what a mouthful! That is a valid structure for an object. Given that functions are also objects, this applies also to functions. When used this way, it is known as a **recursive function** (i.e., a function, that calls itself).

    !!! warning "Use sparingly"

        These constructs often require lots of tinkering and can lead to more problems if they are not coded right. We certainly do not want a function that runs *ad inifinitum*!

    An simple example for this is the factorial. This is defined:

    $$
    n! = n \times (n-1) \times (n-2) \times (n-3) \times ... \times 2 \times 1
    $$

    In code, we can construct:

    !!! r-project "code"

        ```r linenums="1"
        fr <- function(x) {
          if (x > 0) {
            x * fr(x-1)
          } else {
            return(1)
          }
        }

        fr(4)
        ```

        > ```
        > [1] 24
        > ```

## Code in action: A function for $\alpha$-diversity

### How diverse is a sampled community?
    
This is likely the first question one asks when considering community ecology of any environment. A direct measure *diversity within a sample* (also known as *$\alpha$-diversity*) is richness (often denoted $q$ or $S$), which is the tally of number of species/taxonomic units present in any given sample. While simple and intuitive, it is heavily influenced by rare taxonomic units (as is often the case in microbiome samples). Therefore, other metrics which account for the *uneven distribution* of taxonomic units are also reported alongside richness. Popular options are:
    
**Shannon's index, $\textrm{H}$**

$$
\large
\textrm{H} = - \sum_{i=1}^{q} {p_i} \log {p_i}
$$

Where $p_i$ is the proportion of the $i$<sup>th</sup> organism relative to the sample total (also known as the relative frequency of the organism).

**Inverse Simpson's concentration index, $D$**

$$
\large
D = \frac{1}{\lambda}
$$
    
Where the concentration index $\lambda$ is defined as
    
$$
\large
\lambda = \sum_{i=1}^{q} {p_i}^2
$$

If you are mathematically inclined, you might observe that these indices give more weight to abundant taxonomic units and that weighting is higher for $D$ than for $\textrm{H}$.

If you are *not* mathematically inclined, or you are busy focusing on learning coding today, don't worry about understanding the math for now - it's enough to know "It's a formula". 

## Step 1: Start small

Lets start by writing a function that calculates richness. Recall that this is the number of taxonomic units present in the sample (i.e., the number of non-zero elements in a numeric vector). We will also create a test vector so we can test our function.

!!! r-project "code"

    ```r linenums="1"
    # Create test vector based on a column in asv
    test_sample <- asv$AS1A3

    # Write richness function
    alpha_diversity <- function(x) {
      sum(x > 0)
    }

    # Test function
    alpha_diversity(test_sample)
    ```

    > ```
    > [1] 1149
    > ```

## Step 2: Add arguments as required

We know from the preamble above that $\textrm{H}$ and $D$ are also useful metrics to look at. Lets incorporate them into our function.

!!! r-project "code"

    ```r linenums="1"
    alpha_diversity <- function(x, metric) {
    
      # Richness
      q <- sum(x > 0)
    
      if (metric == "richness") {
        return(q)
      }
    
      # Relative frequency
      p_i <- x / sum(x)
    
      # Operation for Shannon's index
      # sum(na.rm = TRUE) to account for NAs as a result of log(0)
      if (metric == "shannon") {
        H <- -sum(p_i * log(p_i), na.rm = TRUE)
        return(H)
      }
    
      # Operation for Inverse Simpson's
      if (metric == "simpson") {
        D <- sum(p_i ^ 2) ^ -1
        return(D)
      }
    
    }

    alpha_diversity(test_sample, metric = "richness")
    alpha_diversity(test_sample, metric = "shannon")
    alpha_diversity(test_sample, metric = "simpson")
    ```

    > ```
    > [1] 1149
    > [1] 6.649886
    > [1] 468.1816
    > ```

Notice that for shared variables like `p_i`, they are placed outside of conditional statements. This reduces code redundancies. Also, in this step, we are introduced to a new function: `return()`. By default, the function will evaluate all code in its "body" and return the result of the last expression. `return()` literally returns the result of the evaluated expression, regardless of its position in the code.

## Step 3: Refine function

While the function we wrote is pretty good, there are some small improvements we can make:

* **Multiple `return()`** Ideally it should only have one. This is because if the user picks richness, there should be no further evaluation of the function code below richness, thus saving time and computation. Although this function (and the data) is so small that computational efficiency is of minimal concern, the thought of wasteful computation should be part of your function writing consideration.
* **Selection of log bases** Traditionally, the log base of Shannon's index has always been $e$. However, one might want to use a different log base, perhaps as a comparison against another study which uses a different base.
* **Redundant variables** While the notation of $\textrm{H}$ and $D$ is useful to us in differentiating the indices in mathematical notation, it is a redundancy in the code. The decision to return either indices is already managed by the conditional statements. 

!!! r-project "code"

    ```r linenums="1"
    alpha_diversity <- function(x, metric, base = exp(1)) {
    
      # Richness
      q <- sum(x > 0)
    
      if (metric == "richness") {
        return(q)
      }
    
      # Relative frequency
      p_i <- x / sum(x)
    
      # Operation for Shannon's index
      # sum(na.rm = TRUE) to account for NAs as a result of log(0)
      if (metric == "shannon") {
        H <- -sum(p_i * log(p_i, base = base), na.rm = TRUE)
      } 
    
      # Operation for Inverse Simpson's
      if (metric == "simpson") {
        H <- sum(p_i ^ 2) ^ -1
      }
    
      # Return result
      H
    
    }
    
    alpha_diversity(test_sample, metric = "richness")
    alpha_diversity(test_sample, metric = "shannon")
    alpha_diversity(test_sample, metric = "shannon", base = 2)
    alpha_diversity(test_sample, metric = "simpson")
    ```

    > ```
    > [1] 1149
    > [1] 6.649886
    > [1] 9.593758
    > [1] 468.1816
    > ```

## Step 4: Defend function

Our function has held up well under ideal conditions. Let's imagine using this function under less than ideal scenarios (dirty data, incorrect types, etc.). What are some of the pitfalls you can think of with the function we wrote?

??? warning "Possible pitfalls"

    1. While we have guarded our function against `NA`s resulting from `log(0)`, there remains the problem of negative numbers. Both richness and Simpson index will continue to be calculated without error or warning, even if it does not make sense to do so.
    2. If the data was supposed to be numeric but was read incorrectly and coerced to become a character, how would we handle that?
    3. How would we handle missing values in general?

To address these concerns, we will take hints from a concept called **defensive programming**. An aspect of defensive programming is preventing incorrect usage of code by "failing fast". This is where errors are produced and code will stop running if inputs are incorrect or do not make sense. In practice, that means we need to be strict with inputs and how they are to be pre-processed. We also need to balance this with the prospect that users know what they are doing and provide flexible implementation when needed. 

In this case, we need to address:

!!! success "Improvements to make"

    1. Negative numbers makes no sense for the calculation of richness and relative frequencies. Therefore, we must insist on the provision of strictly zero or positive numbers as inputs and produce an error that stops further code execution if a negative number is found.
    2. Regardless of the reason for non-numeric inputs, calculations only make sense for numeric data. This is non-negotiable. Thus, we must write code the produces an error if non-numeric inputs are detected.
    3. We can be flexible around missing values. For these indices, there is no way to differentiate a missing observation versus a zero count. Therefore, we can warn the user that there are missing values and that they are removed prior to calculation.

!!! r-project "code"

    ```r linenums="1"
    alpha_diversity <- function(x, metric, base = exp(1)) {
    
      # Warns for missing values
      if (anyNA(x)) {
        warning("x contains missing values. These were removed prior to calculations.")
        x <- x[!is.na(x)]
      }
    
      # Ensure positive numeric inputs
      if (!is.numeric(x) | any(x < 0)) {
        stop("x must be positive numeric values!")
      }
    
      # Richness
      q <- sum(x > 0)
    
      if (metric == "richness") {
        return(q)
      }
    
      # Relative frequency
      p_i <- x / sum(x)
    
      # Operation for Shannon's index
      # sum(na.rm = TRUE) to account for NAs as a result of log(0)
      if (metric == "shannon") {
        H <- -sum(p_i * log(p_i, base = base), na.rm = TRUE)
      } 
    
      # Operation for Inverse Simpson's
      if (metric == "simpson") {
        H <- sum(p_i ^ 2) ^ -1
      }
    
      H
    
    }
    ```

    We will also generate some new test vectors to simulate problematic inputs of missing values, negative numbers or character values.

    ```r linenums="1"
    test_missing <- c(test_sample, NA, NA)
    test_negative <- c(test_sample, -46)
    test_character <- as.character(test_sample)

    tail(test_missing)
    tail(test_negative)
    tail(test_character)
    ```

    > ```
    > [1]  0  0  0  0 NA NA
    > [1]   0   0   0   0   0 -46
    > [1] "0" "0" "0" "0" "0" "0"
    > ```

    Now test the new function:

    ```r linenums="1"
    alpha_diversity(test_missing, "richness")
    alpha_diversity(test_negative, "shannon")
    alpha_diversity(test_character, "simpson")
    ```

    > ```
    > [1] 1149
    > Warning message:
    > In alpha_diversity(test_missing, "richness") :
    >   x contains missing values. These were removed prior to calculations.
    >
    > Error in alpha_diversity(test_negative, "shannon") : 
    >   x must be positive numeric values!
    > 
    > Error in alpha_diversity(test_character, "simpson") : 
    >   x must be positive numeric values!
    > ```

## Improving function writing

**Read existing functions (i.e., other people's code)**

This is often the best way to improve how you write functions. You can inspect the code for most functions by calling the function name without the brackets:

!!! r-project "code"

    ```r
    # Looking at the source code for the function that calculates an interquartile range
    IQR
    ```

    > ```
    > function (x, na.rm = FALSE, type = 7) 
    > diff(quantile(as.numeric(x), c(0.25, 0.75), na.rm = na.rm, names = FALSE, 
    >     type = type))
    > <bytecode: 0x0000023a58a9af60>
    > <environment: namespace:stats>
    > ```


Some functions are handled differently depending on the input. If we call the functions directly like above, we might get this output:

!!! r-project "code"

    ```r
    anova
    ```

    > ```
    > function (object, ...) 
    > UseMethod("anova")
    > <bytecode: 0x0000023a3f9e4838>
    > <environment: namespace:stats>
    > ```

In this case, use a combination of `methods()` and `getAnywhere()` to find the source code.

!!! r-project "code"

    ```r
    methods("anova")
    ```

    > ```
    > [1] anova.glm*     anova.glmlist* anova.lm*      anova.lmlist*  anova.loess*   anova.mlm*     anova.mlmlist*
    > [8] anova.nls*    
    > see '?methods' for accessing help and source code
    > ```
    Pick one of the outputs as the input for `getAnywhere()`.
    ```r
    getAnywhere("anova.lm")
    ```
    > ```
    > A single object matching anova.lm was found
    > It was found in the following places
    >   registered S3 method for anova from namespace stats
    >   namespace:stats
    > with value
    > 
    > function (object, ...) 
    > {
    >     if (length(list(object, ...)) > 1L) 
    >         return(anova.lmlist(object, ...))
    >     if (!inherits(object, "lm")) 
    >         warning("calling anova.lm(<fake-lm-object>) ...")
    >     w <- object$weights
    >     ssr <- sum(if (is.null(w)) object$residuals^2 else w * object$residuals^2)
    >     mss <- sum(if (is.null(w)) object$fitted.values^2 else w * 
    >         object$fitted.values^2)
    >     if (ssr < 1e-10 * mss) 
    >         warning("ANOVA F-tests on an essentially perfect fit are unreliable")
    >     dfr <- df.residual(object)
    >     p <- object$rank
    >     if (p > 0L) {
    >         p1 <- 1L:p
    >         comp <- object$effects[p1]
    >         asgn <- object$assign[qr.lm(object)$pivot][p1]
    >         nmeffects <- c("(Intercept)", attr(object$terms, "term.labels"))
    >         tlabels <- nmeffects[1 + unique(asgn)]
    >         ss <- c(vapply(split(comp^2, asgn), sum, 1), ssr)
    >         df <- c(lengths(split(asgn, asgn)), dfr)
    >     }
    >     else {
    >         ss <- ssr
    >         df <- dfr
    >         tlabels <- character()
    >     }
    >     ms <- ss/df
    >     f <- ms/(ssr/dfr)
    >     P <- pf(f, df, dfr, lower.tail = FALSE)
    >     table <- data.frame(df, ss, ms, f, P)
    >     table[length(P), 4:5] <- NA
    >     dimnames(table) <- list(c(tlabels, "Residuals"), c("Df", 
    >         "Sum Sq", "Mean Sq", "F value", "Pr(>F)"))
    >     if (attr(object$terms, "intercept")) 
    >         table <- table[-1, ]
    >     structure(table, heading = c("Analysis of Variance Table\n", 
    >         paste("Response:", deparse(formula(object)[[2L]]))), 
    >         class = c("anova", "data.frame"))
    > }
    > <bytecode: 0x0000025be02abf58>
    > <environment: namespace:stats>
    > ```

The output tells us that there is a function called `anova.lm` within the package `stats` with the function as defined in the body. 

??? tip "Why the different options for `anova()`?"

    Some functions can produce different outputs depending on input type (or class). We used `anova()` as an example as the Analysis of Variance can be performed on the outputs of different models: linear, generalised linear, compare multiple models, etc (read the help page for `lm()` and you will find that there is a statement under the **Value** section: `lm returns an object of class "lm" or for multivariate (multiple) responses of class c("mlm", "lm").`). However, different classes of models require different calculation to perform the same kind of analysis. Therefore, instead of storing multiple dizzying `if...else` statements (the body of the function is sufficiently voluminous!), the different functions are stored as `methods` for the different `class`. This means that whenever we call `anova()` with an input that was generated using a `glm()`, it will detect that the input carries the `class` of `glm` and dispatch (read: use) the appropriate `method` to handle it.

**Write according to needs**

We strive to write functions to be as predictable and elegant as possible. However, this is only a guide. Depending on our needs, the syntax of our functions can and should change. If we are at the stage of exploratory data analysis, we should be coding for flexibility. At this early stage, if things do fail, it is not a dependency issue and we can troubleshoot as needed. Furthermore, if we are testing code on smaller data sets, we do not need to be as mindful of being computationally efficient. However, as we get ready to scale our analyses workflows that have input-output dependencies (i.e., production level code), we need to change our priorities. Here, the priorities should be code safety (predictable In/Oout, no code running *ad infinitum*, redundancies in checking I/O,), efficiency (i.e., use efficient and benchmarked algorithms/functions/packages, avoid code that produced side effects), ease of troubleshooting (i.e., use modular abstractions, informative error and warning messages), and readability (i.e., commented code, reduce shorthands if possible).

**Break them!**

There is no better way to know what our functions are doing than by purposefully breaking them. What would happen if we provided a nonsense input? Will it produce a valid output? Will it error out? In addition, stress testing functions (especially complex ones) is helpful. Are there portions of the code that is inefficient/stalling? How much data is too much data? When writing multiple functions (some of which might be dependent on each other), this can help us to identify weaknesses and improper use.

-->
