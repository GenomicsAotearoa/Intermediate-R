# Functions and conditional statements

!!! note "Learning objectives"

    * Write custom functions
    * Use conditional statements to control execution of code
    * Apply concepts in defensive programming to function writing

## I can make those?!

Functions are integral components of R. They are what make it possible to do, well, everything! Even addition `+` is a function: 

!!! r-project "code"

    ```r
    mode(`+`)
    str(`+`)
    ```

    > ```
    > [1] "function"
    > function (e1, e2)
    > ```

Like all things in R, a function is also an object (we'll see what other implications that has later). Think of functions as verbs. They are pieces of code that do something and produce an outcome (sometimes invisibly). Just as you can assign an object to a variable, you can assign entire chunks of code that "does something" to a object. In R, that is what a function is: an object that does something. So yes, you can write functions! 

In this lesson, we will learn to construct custom functions and conditional statements. Conditional statements are code chunks that helps us handle decision making according to rules. Then, we will write a custom function that calculates different alpha diversity metrics (a staple in any ecological analysis). As part of writing the custom function, we will learn a little bit about defensive programming and how that provides a practical foundation for writing resilient and reliable functions.

## Anatomy of a function

Here is a pseudocode representation of assigning a function:

```r
my_function <- function(<arguments>) {

  <do something>

}
```

All functions start with the `function` call, followed by arguments enveloped between parentheses, and finally the expression (the `<do something>` part of the pseudocode above). This defines what the function does. The expression need not be wrapped in curly brackets `{}` so long as it is on the same line as the `function` call. However, for long expressions, this makes code more legible such that the reader understands that the lines of code wrapped in `{...}` are part of the function object. Here is an example of a function that does $\sqrt{2(x + 1)}$:

!!! r-project "code"

    ```r
    f1 <- function(x) sqrt(2 * (x + 1))

    f1(x = 3)
    ```

    > ```
    > [1] 2.828427
    > ```

!!! tip "`function` shorthand"

    The `function` call can also be shortened to just a backslash `\` to mean the same thing. For example, this is equivalent to the code above:

    !!! r-project "code"

        ```r
        f1 <- \(x) sqrt(2 * (x + 1))
        ```
    
    This makes it easier to write short functions on the fly for interactive use.

**Default values**

Many pre-built functions that we use on a day-to-day basis takes one argument as user input. However, this is usually a convenience. For example:

!!! r-project "code"

    ```r
    log(5)
    ```

    > ```
    > [1] 1.609438
    > ```

By default, the `log()` function returns the natural log (base $e$). If we access its help page, we find that we can specify another base for the logarithm conversion.

!!! r-project "code"

    ```r
    log(5, base = 5)
    ```

    > ```
    > [1] 1
    > ```

To set default values for our custom functions, we need only place the value when configuring the arguments. The following function cubes `x` by default, but can take other values to exponentiate `x`.

!!! r-project "code"

    ```r
    f2 <- function(x, p = 3) x ^ p
    f2(3)
    f2(3, p = 5)
    ```

    > ```
    > [1] 27
    > [1] 243
    > ```

## Conditional execution

Before continuing on our journey to write functions, we need to take a brief look at conditional statements. These are common across all programming languages; you may know them as `if-else` statements. They are important constructs that control the flow of operations at all levels, be it within a function or a script, and even across scripts. In their most fundamental form, they resemble this:

```r
if (<predicate>) {

  <expression_1>

} else {

  <expression_2>

}
```

The code above means:

> If the predicate returns a TRUE, run code defined by `<expression_1>`, else run `<expression_2>`.

??? note "Predicate and predicate functions"

    A predicate is a statement or function that evaluation that returns **a single** `TRUE` or `FALSE`. For example, this is a predicate that evaluates if `x` is larger than 5:
    
    ```r
    x > 5
    ```

    If we set `x <- 10`, the code will return a `TRUE`.

    R has many built-in predicate functions (i.e., functions that evaluate a statement or object and returns a `TRUE`/`FALSE`) are often prefixed using `is.<something>()`. For example:

    !!! r-project "code"

        ```r
        x <- 9
        tim <- "Tim is eating"
        y <- 1:6

        # Predicate function
        is.character(x)
        is.character(tim)
        is.character(y)
        is.numeric(y)
        ```

        > ```
        > [1] FALSE
        > [1] TRUE
        > [1] FALSE
        > [1] TRUE
        > ```

    Notice that regardless of the length of the vector, the predicate functions return only one Boolean variable. This is important for conditional statements as it can only evaluate predicates and not a vector of Boolean variables.

To better illustrate what conditional statements do, lets construct an `if...else` to evaluate the following question:

Did we recruit enough reads to perform meaningful ecological analyses?

Lets say that a total read count of at least 500 is required for further analysis and that any value lower than or equal to 500 means we must remedy procedures in handling that sample. Here, our predicate is: `sum(<sample_column>) > 500`. 

!!! r-project "code"

    ```r
    reads_AS1A1 <- sum(asv$AS1A1)

    if (reads_AS1A1 > 500) {
      # If the predicate is TRUE, do this
      print(
        paste("This sample has", reads_AS1A1, "reads.")
      )
      print("It has sufficient reads.")

    } else {
      # If the predicate is FALSE, do this
      print("This sample has insufficient reads.")

    }
    ```

    > ```
    > [1] "This sample has 5610 reads."
    > [1] "It has sufficient reads."
    > ```

### Nested statements

If we had multiple predicates that needs to be chained one after another, we can construct nested conditional statements:

```r
if (<predicate>) {
  
  <expression_1>

} else if (<predicate>) {
  
  <expression_2>

} else {

  <expression_3>

}
```

For example:

!!! r-project "code"

    ```r
    reads_S3C3 <- sum(asv$S3C3)
    reads_S3C3

    if (reads_S3C3 > 5000) {
    
      print("Abundant reads")
    
    } else if (reads_S3C3 > 1000 & reads_S3C3 <= 5000) {
    
      print("High number of reads")
    
    } else if (reads_S3C3 > 500 & reads_S3C3 <= 1000) {
    
      print("Sufficient reads")
    
    } else {
    
      print("Insufficient reads")

    }
    ```

    > ```
    > [1] 870
    > [1] "Sufficient reads"
    > ```

When using nested statements, keep in mind that order matters. This means that if the first predicate is `TRUE`, none of the statements below it will be evaluated.

### Vectorised conditional statements

These are functions that 

1. Takes a vector of Boolean variables (or an expression that produces them)
2. Returns an outcome for each element if it is TRUE
3. Returns another outcome for each element if it FALSE

For binary decisions (i.e., `if (predicate) {...} else {...}`), there are two functions:

* `ifelse()`: part of base R
* `if_else()`: part of `dplyr`

They can both return short, simple variables:

!!! r-project "code"

    ```r
    read_sums <- colSums(asv[, -1])

    ifelse(
      read_sums > 5000, 
      "Sufficient reads", 
      "Insufficient reads"
    ) %>%
      tail()
    ```

    > ```
    >                  AS2C1                  AS2C2                  AS2C3                   S3C1 
    > "High number of reads" "High number of reads" "High number of reads" "High number of reads" 
    >                   S3C2                   S3C3 
    > "High number of reads"          "Check reads"
    > ```

or return values after evaluating longer expressions:

!!! r-project "code"

    ```r
    if_else(
      read_sums > 1000,
      {
        a <- sqrt(read_sums)
        paste("The square root of this is", a)
      },
      {
        a <- read_sums ^ (1/3)
        paste("The cube root of this is", a)
      }
    ) %>%
      tail()
    ```

    > ```
    >                                         AS2C1                                         AS2C2 
    > "The square root of this is 78.4283112147648" "The square root of this is 75.6174583016383" 
    >                                         AS2C3                                          S3C1 
    > "The square root of this is 82.4075239283404" "The square root of this is 33.5111921602321" 
    >                                          S3C2                                          S3C3 
    > "The square root of this is 60.5061980296234"   "The cube root of this is 9.54640270936004"
    > ```

For nested statements, there is `case_when()` from `dplyr` that takes the form of:

```r
case_when(
  <predicate_1> ~ <expression_1>,
  <predicate_2> ~ <expression_2>,
  <predicate_3> ~ <expression_3>,
  ...
  TRUE ~ <default_value>
)
```

### Practical usage

**`else` is optional**

For most use cases, it is sufficient (and less redundant) to only construct the `if (<predicate>) {<expression>}` part of the statement. Unless there is a good reason to pick one option over the other, the `else {<expression>}` is optional and can be entirely omitted. This is because R will only execute the expression within the statement if the predicate is `TRUE`. For this reason, it is very common to see the `else {}` omitted in functions.

**Nested statements are rarely a good idea**

Often, nested statements are not helpful. In the best of cases, you may have a reason to use them. For example, there may be genuine need for a hierarchical way of evaluating the flow of data where some collection of thresholds warrant a different method of processing data downstream. However, this can lead to messy code that ends up being illegible and the results can be cryptic (i.e., the reader may not intuitively know where the results come from based on the chain of statements). 

It is better to break up the expression and set them as different functions called under different scenarios. This modular structure means that you not only remove potential redundancies, but it also improves code legibility where readers can easily determine the functions that are being called, the expression the function uses, and the intended result.

**Vectorise for one-off use cases**

R is particularly proficient when we use functions that take in vectors. In cases where you need to `mutate()` a column in a data frame (e.g., replacing values based on pattern searches and return a variable), the vectorised `if_else()` and `case_when()` are your friends. Also, I prefer to use `if_else()` as opposed to `ifelse()` as it can handle missing values and produce consistent output types, a coveted feature in ensuring input-output consistency.

## Functions are objects too

!!! note ""

    This section is a little more abstract than previous sections and might take a while to get our heads around. However, it is nonetheless useful to know how functions can behave like objects so that we can use them more flexibly.

At the beginning of this lesson, we came across the concept that functions are objects. In examples above, we assign names to functions in order to call them. That is one property of an object: *they can be named*. However, there are also objects that we use on the fly without naming them. Consider the following:

```r
c("A", "B", "D", "F")
```

If you run the above, it will print out the letters `A`, `B`, `D`, and `F`. We haven't named them, and yet we can use them. The same goes for functions, but the syntax is slightly different:

!!! r-project "code"

    ```r
    (\(x, y) x + y)(x = 3, y = 5)
    ```

    > ```
    > [1] 8
    > ```

We've encased the function itself in brackets `()`, supplied it with the required arguments, and it provides an output. This is known as an **anonymous function**. Keep this in mind as it will be quite prominent in the next lesson.

Another property of an object is that *they can be stored*. While it is not possible to store a function in a vector, it is possible to store them in a list. This is a valid way to store functions:

```r
flist <- list(
  \(x) x + 1,
  \(x) x + 2,
  \(x) x ^ 3
)
flist
```

```
[[1]]
\(x) x + 1

[[2]]
\(x) x + 2

[[3]]
\(x) x ^ 3
```

With this structure, you can iterate through the list and generate different outputs depending on the function applied.

You can also use it as input to another function. For example, if you pass that into `class()` or `mode()`, it will tell you it is a character vector. When you pass a function into `class()`, it will tell you that it is a function (no surprise there).

!!! r-project "code"

    ```r
    class(f1)
    ```

    > ```
    > [1] "function"
    > ```

That reveals another aspect of functions: they can be *treated as input*.

We will learn about iterations in the next lesson, but to showcase the points:

* functions can be stored (thus iterated)
* functions can be treated as input

!!! r-project "code"

    ```r
    map(flist, \(x) x(2))
    ```

    > ```
    > [[1]]
    > [1] 3
    > 
    > [[2]]
    > [1] 4
    > 
    > [[3]]
    > [1] 8
    > ```

!!! note "Recursive functions"

    The last property of an object is that for some types, they can exist inside themselves. Consider a nested list:

    ```r linenums="1"
    nl <- list(1, "a", \(x) x + 4)
    nl <- list(
      nl = list(
        nl = list(
          nl = nl
        )
      )
    )
    ```

    The above is a list object, in it's own list object, it it's own list object, in it's own list object. Phew what a mouthful! That is a valid structure for an object. Given that functions are also objects, this applies also to functions. When used this way, it is known as a **recursive function** (i.e., a function, that calls itself).

    !!! warning "Use sparingly"

        These constructs often require lots of tinkering and can lead to more problems if they are not coded right. We certainly do not want a function that runs *ad inifinitum*!

    An simple example for this is the factorial. This is defined:

    $$
    n! = n \times (n-1) \times (n-2) \times (n-3) \times ... \times 2 \times 1
    $$

    In code, we can construct:

    !!! r-project "code"

        ```r linenums="1"
        fr <- function(x) {
          if (x > 0) {
            x * fr(x-1)
          } else {
            return(1)
          }
        }

        fr(4)
        ```

        > ```
        > [1] 24
        > ```


<!-- Could add a sub-section on recursive functions using a limited integral or factorial as an example. -->

## Code in action: A function for $\alpha$-diversity

### How diverse is a sampled community?
    
This is likely the first question one asks when considering community ecology of any environment. A direct measure *diversity within a sample* (also known as *$\alpha$-diversity*) is richness (often denoted $q$ or $S$), which is the tally of number of species/taxonomic units present in any given sample. While simple and intuitive, it is heavily influenced by rare taxonomic units (as is often the case in microbiome samples). Therefore, other metrics which account for the *uneven distribution* of taxonomic units are also reported alongside richness. Popular options are:
    
**Shannon's index, $\textrm{H}$**

$$
\large
\textrm{H} = - \sum_{i=1}^{q} {p_i} \log {p_i}
$$

Where $p_i$ is the proportion of the $i$<sup>th</sup> organism relative to the sample total (also known as the relative frequency of the organism).

**Inverse Simpson's concentration index, $D$**

$$
\large
D = \frac{1}{\lambda}
$$
    
Where the concentration index $\lambda$ is defined as
    
$$
\large
\lambda = \sum_{i=1}^{q} {p_i}^2
$$

If you are mathematically inclined, you might observe that these indices give more weight to abundant taxonomic units and that weighting is higher for $D$ than for $\textrm{H}$.

## Step 1: Start small

Lets start by writing a function that calculates richness. Recall that this is the number of taxonomic units present in the sample (i.e., the number of non-zero elements in a numeric vector). We will also create a test vector so we can test our function.

!!! r-project "code"

    ```r linenums="1"
    # Create test vector based on a column in asv
    test_sample <- asv$AS1A3

    # Write richness function
    alpha_diversity <- function(x) {
      sum(x > 0)
    }

    # Test function
    alpha_diversity(test_sample)
    ```

    > ```
    > [1] 1149
    > ```

## Step 2: Add arguments as required

We know from the preamble above that $\textrm{H}$ and $D$ are also useful metrics to look at. Lets incorporate them into our function.

!!! r-project "code"

    ```r linenums="1"
    alpha_diversity <- function(x, metric) {
    
      # Richness
      q <- sum(x > 0)
    
      if (metric == "richness") {
        return(q)
      }
    
      # Relative frequency
      p_i <- x / sum(x)
    
      # Operation for Shannon's index
      # sum(na.rm = TRUE) to account for NAs as a result of log(0)
      if (metric == "shannon") {
        H <- -sum(p_i * log(p_i), na.rm = TRUE)
        return(H)
      }
    
      # Operation for Inverse Simpson's
      if (metric == "simpson") {
        D <- sum(p_i ^ 2) ^ -1
        return(D)
      }
    
    }

    alpha_diversity(test_sample, metric = "richness")
    alpha_diversity(test_sample, metric = "shannon")
    alpha_diversity(test_sample, metric = "simpson")
    ```

    > ```
    > [1] 1149
    > [1] 6.649886
    > [1] 468.1816
    > ```

Notice that for shared variables like `p_i`, they are placed outside of conditional statements. This reduces code redundancies. Also, in this step, we are introduced to a new function: `return()`. By default, the function will evaluate all code in its "body" and return the result of the last expression. `return()` literally returns the result of the evaluated expression, regardless of its position in the code.

## Step 3: Refine function

While the function we wrote is pretty good, there are some small improvements we can make:

* **Multiple `return()`** Ideally it should only have one. This is because if the user picks richness, there should be no further evaluation of the function code below richness, thus saving time and computation. Although this function (and the data) is so small that computational efficiency is of minimal concern, the thought of wasteful computation should be part of your function writing consideration.
* **Selection of log bases** Traditionally, the log base of Shannon's index has always been $e$. However, one might want to use a different log base, perhaps as a comparison against another study which uses a different base.
* **Redundant variables** While the notation of $\textrm{H}$ and $D$ is useful to us in differentiating the indices in mathematical notation, it is a redundancy in the code. The decision to return either indices is already managed by the conditional statements. 

!!! r-project "code"

    ```r linenums="1"
    alpha_diversity <- function(x, metric, base = exp(1)) {
    
      # Richness
      q <- sum(x > 0)
    
      if (metric == "richness") {
        return(q)
      }
    
      # Relative frequency
      p_i <- x / sum(x)
    
      # Operation for Shannon's index
      # sum(na.rm = TRUE) to account for NAs as a result of log(0)
      if (metric == "shannon") {
        H <- -sum(p_i * log(p_i, base = base), na.rm = TRUE)
      } 
    
      # Operation for Inverse Simpson's
      if (metric == "simpson") {
        H <- sum(p_i ^ 2) ^ -1
      }
    
      # Return result
      H
    
    }
    
    alpha_diversity(test_sample, metric = "richness")
    alpha_diversity(test_sample, metric = "shannon")
    alpha_diversity(test_sample, metric = "shannon", base = 2)
    alpha_diversity(test_sample, metric = "simpson")
    ```

    > ```
    > [1] 1149
    > [1] 6.649886
    > [1] 9.593758
    > [1] 468.1816
    > ```

## Step 4: Defend function

Our function has held up well under ideal conditions. Let's imagine using this function under less than ideal scenarios (dirty data, incorrect types, etc.). What are some of the pitfalls you can think of with the function we wrote?

??? warning "Possible pitfalls"

    1. While we have guarded our function against `NA`s resulting from `log(0)`, there remains the problem of negative numbers. Both richness and Simpson index will continue to be calculated without error or warning, even if it does not make sense to do so.
    2. If the data was supposed to be numeric but was read incorrectly and coerced to become a character, how would we handle that?
    3. How would we handle missing values in general?

To address these concerns, we will take hints from a concept called **defensive programming**. An aspect of defensive programming is preventing incorrect usage of code by "failing fast". This is where errors are produced and code will stop running if inputs are incorrect or do not make sense. In practice, that means we need to be strict with inputs and how they are to be pre-processed. We also need to balance this with the prospect that users know what they are doing and provide flexible implementation when needed. 

In this case, we need to address:

!!! success "Improvements to make"

    1. Negative numbers makes no sense for the calculation of richness and relative frequencies. Therefore, we must insist on the provision of strictly zero or positive numbers as inputs and produce an error that stops further code execution if a negative number is found.
    2. Regardless of the reason for non-numeric inputs, calculations only make sense for numeric data. This is non-negotiable. Thus, we must write code the produces an error if non-numeric inputs are detected.
    3. We can be flexible around missing values. For these indices, there is no way to differentiate a missing observation versus a zero count. Therefore, we can warn the user that there are missing values and that they are removed prior to calculation.

!!! r-project "code"

    ```r linenums="1"
    alpha_diversity <- function(x, metric, base = exp(1)) {
    
      # Warns for missing values
      if (anyNA(x)) {
        warning("x contains missing values. These were removed prior to calculations.")
        x <- x[!is.na(x)]
      }
    
      # Ensure positive numeric inputs
      if (!is.numeric(x) | any(x < 0)) {
        stop("x must be positive numeric values!")
      }
    
      # Richness
      q <- sum(x > 0)
    
      if (metric == "richness") {
        return(q)
      }
    
      # Relative frequency
      p_i <- x / sum(x)
    
      # Operation for Shannon's index
      # sum(na.rm = TRUE) to account for NAs as a result of log(0)
      if (metric == "shannon") {
        H <- -sum(p_i * log(p_i, base = base), na.rm = TRUE)
      } 
    
      # Operation for Inverse Simpson's
      if (metric == "simpson") {
        H <- sum(p_i ^ 2) ^ -1
      }
    
      H
    
    }
    ```

    We will also generate some new test vectors to simulate problematic inputs of missing values, negative numbers or character values.

    ```r linenums="1"
    test_missing <- c(test_sample, NA, NA)
    test_negative <- c(test_sample, -46)
    test_character <- as.character(test_sample)

    tail(test_missing)
    tail(test_negative)
    tail(test_character)
    ```

    > ```
    > [1]  0  0  0  0 NA NA
    > [1]   0   0   0   0   0 -46
    > [1] "0" "0" "0" "0" "0" "0"
    > ```

    Now test the new function:

    ```r linenums="1"
    alpha_diversity(test_missing, "richness")
    alpha_diversity(test_negative, "shannon")
    alpha_diversity(test_character, "simpson")
    ```

    > ```
    > [1] 1149
    > Warning message:
    > In alpha_diversity(test_missing, "richness") :
    >   x contains missing values. These were removed prior to calculations.
    >
    > Error in alpha_diversity(test_negative, "shannon") : 
    >   x must be positive numeric values!
    > 
    > Error in alpha_diversity(test_character, "simpson") : 
    >   x must be positive numeric values!
    > ```

## Improving function writing

**Read existing functions (i.e., other people's code)**

This is often the best way to improve how to write functions. You can inspect the code for most functions by calling the function name without the brackets:

!!! r-project "code"

    ```r
    # Looking at the source code for the function 
    # that calculates an interquartile range
    IQR
    ```

    > ```
    > function (x, na.rm = FALSE, type = 7) 
    > diff(quantile(as.numeric(x), c(0.25, 0.75), na.rm = na.rm, names = FALSE, 
    >     type = type))
    > <bytecode: 0x0000023a58a9af60>
    > <environment: namespace:stats>
    > ```


Some functions are handled differently depending on the input. If we call the functions directly like above, we might get this output:

!!! r-project "code"

    ```r
    anova
    ```

    > ```
    > function (object, ...) 
    > UseMethod("anova")
    > <bytecode: 0x0000023a3f9e4838>
    > <environment: namespace:stats>
    > ```

In this case, use a combination of `methods()` and `getAnywhere()` to find the source code.

!!! r-project "code"

    ```r
    methods("anova")
    ```

    > ```
    > [1] anova.glm*     anova.glmlist* anova.lm*      anova.lmlist*  anova.loess*   anova.mlm*     anova.mlmlist*
    > [8] anova.nls*    
    > see '?methods' for accessing help and source code
    > ```
    Pick one of the outputs as the input for `getAnywhere()`.
    ```r
    getAnywhere("anova.lm")
    ```
    > ```
    > A single object matching ‘anova.lm’ was found
    > It was found in the following places
    >   registered S3 method for anova from namespace stats
    >   namespace:stats
    > with value
    > 
    > function (object, ...) 
    > {
    >     if (length(list(object, ...)) > 1L) 
    >         return(anova.lmlist(object, ...))
    >     if (!inherits(object, "lm")) 
    >         warning("calling anova.lm(<fake-lm-object>) ...")
    >     w <- object$weights
    >     ssr <- sum(if (is.null(w)) object$residuals^2 else w * object$residuals^2)
    >     mss <- sum(if (is.null(w)) object$fitted.values^2 else w * 
    >         object$fitted.values^2)
    >     if (ssr < 1e-10 * mss) 
    >         warning("ANOVA F-tests on an essentially perfect fit are unreliable")
    >     dfr <- df.residual(object)
    >     p <- object$rank
    >     if (p > 0L) {
    >         p1 <- 1L:p
    >         comp <- object$effects[p1]
    >         asgn <- object$assign[qr.lm(object)$pivot][p1]
    >         nmeffects <- c("(Intercept)", attr(object$terms, "term.labels"))
    >         tlabels <- nmeffects[1 + unique(asgn)]
    >         ss <- c(vapply(split(comp^2, asgn), sum, 1), ssr)
    >         df <- c(lengths(split(asgn, asgn)), dfr)
    >     }
    >     else {
    >         ss <- ssr
    >         df <- dfr
    >         tlabels <- character()
    >     }
    >     ms <- ss/df
    >     f <- ms/(ssr/dfr)
    >     P <- pf(f, df, dfr, lower.tail = FALSE)
    >     table <- data.frame(df, ss, ms, f, P)
    >     table[length(P), 4:5] <- NA
    >     dimnames(table) <- list(c(tlabels, "Residuals"), c("Df", 
    >         "Sum Sq", "Mean Sq", "F value", "Pr(>F)"))
    >     if (attr(object$terms, "intercept")) 
    >         table <- table[-1, ]
    >     structure(table, heading = c("Analysis of Variance Table\n", 
    >         paste("Response:", deparse(formula(object)[[2L]]))), 
    >         class = c("anova", "data.frame"))
    > }
    > <bytecode: 0x0000025be02abf58>
    > <environment: namespace:stats>
    > ```

The output tells us that there is a function called `anova.lm` within the package `stats` with the function as defined in the body. 

??? tip "Why the different options for `anova()`?"

    Some functions can produce different outputs depending on input type (or class). We used `anova()` as an example as the Analysis of Variance can be performed on the outputs of different models: linear, generalised linear, compare multiple models, etc (read the help page for `lm()` and you will find that there is a statement under the **Value** section: `lm returns an object of class "lm" or for multivariate (‘multiple’) responses of class c("mlm", "lm").`). However, different classes of models require different calculation to perform the same kind of analysis. Therefore, instead of storing multiple dizzying `if...else` statements (the body of the function is sufficiently voluminous!), the different functions are stored as `methods` for the different `class`. This means that whenever we call `anova()` with an input that was generated using a `glm()`, it will detect that the input carries the `class` of `glm` and dispatch (read: use) the appropriate `method` to handle it.

**Write according to needs**

We strive to write functions to be as predictable and elegant as possible. However, this is only a guide. Depending on our needs, the syntax of our functions can and should change. If we are at the stage of exploratory data analysis, we should be coding for flexibility. At this stage, if things do fail, it is not a dependency issue and we can troubleshoot as needed. Furthermore, if we are testing code on smaller data sets, we do not need to be as mindful of being computationally efficient. However, as we get ready to scale our analyses workflows that have input-output dependencies (i.e., production level code), we need to change our priorities. Here, the priorities should be code safety (predictable I/O, no code running *ad infinitum*, redundancies in checking I/O,), efficiency (i.e., use efficient and benchmarked algorithms/functions/packages, avoid code that produced side effects), ease of troubleshooting (i.e., use modular abstractions, informative error and warning messages), and readability (i.e., commented code, reduce shorthands if possible).

**Break them!**

There is no better way to know what our functions are doing than by purposefully breaking them. What would happen if we provided a nonsense input? Will it produce a valid output? Will it error out? In addition, stress testing functions (especially complex ones) is helpful. Are there portions of the code that is inefficient/stalling? How much data is too much data? When writing multiple functions (some of which might be dependent on each other), this can help us to identify weaknesses and improper use.

